{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b469385d",
   "metadata": {},
   "source": [
    "clean\n",
    "cnn: 0.9970\n",
    "abc: 0.9971\n",
    "\n",
    "fgsm\n",
    "cnn: 0.2797\n",
    "abc: 0.5499\n",
    "\n",
    "pgd20\n",
    "cnn: 0.9813\n",
    "abc: 0.9808\n",
    "\n",
    "foolbox:\n",
    "pgd20 alpha=0.1 epsilon=0.1\n",
    "cnn: 0.0242\n",
    "abc: 0.2902\n",
    "\n",
    "fgsm epsilon=0.1\n",
    "cnn: 0.1504\n",
    "abc: 0.8913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fa78c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.tools import dotdict\n",
    "from driver.driver import ABC_Driver\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f3d6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_args = dotdict()\n",
    "\n",
    "mnist_args.name = 'mnist'\n",
    "# mnist_args.device = ['cuda:4', 'cuda:5']\n",
    "mnist_args.device = ['cuda:0']\n",
    "mnist_args.train_batch_size = 120\n",
    "mnist_args.predict_batch_size = 120\n",
    "\n",
    "mnist_args.train_epochs = 30\n",
    "mnist_args.lr = 0.001\n",
    "mnist_args.criterion = 'CE'\n",
    "mnist_args.optimizer = 'Adam'\n",
    "mnist_args.scheduler = 'multistep3'\n",
    "mnist_args.attack = {'fgsm':(0.1,), 'pgd':(0.1,0.1,20), 'deepfool':(0.1,0.1,20), 'apgd-ce':(0.1,)}\n",
    "\n",
    "activation = 'relu'\n",
    "input_channel = 1\n",
    "knpp = [30,60,120,180,240,300]\n",
    "\n",
    "# mnist_args.layers=[\n",
    "#     ('cnn2d', ((input_channel, knpp[0], (7,7), 1, 3, 1, 1), 1, None, None, activation, False)),\n",
    "#     ('atc2d', ((knpp[0], knpp[1], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, True)),\n",
    "#     ('atc2d', ((knpp[1], knpp[2], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, True)),\n",
    "#     ('atc2d', ((knpp[2], knpp[3], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, True)),\n",
    "#     ('atc2d', ((knpp[3], knpp[4], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, True)),\n",
    "#     ('cnn2d', ((knpp[4], knpp[5], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, False)),\n",
    "#     ('cnn2d', ((knpp[-1], knpp[-1], (3,3), 1, 0, 1, knpp[0]), 1, None, None, False, False)),\n",
    "#     ('adptavgpool', (1,1)),\n",
    "#     ('linear', (knpp[-1], 10, (1,2,3)))\n",
    "# ]\n",
    "\n",
    "# mnist_args.layers=[\n",
    "#     ('cnn2d', ((1, 24, (7, 7), 1, 3, 1, 1), 1, None, None, 'relu', False)), \n",
    "#     ('atc2d', ((24, 48, (3, 3), 1, 1, 1, 24), 1, None, None, 'relu', True)), \n",
    "#     ('atc2d', ((48, 96, (3, 3), 1, 1, 1, 24), 1, 'first', (2, 2), 'relu', True)), \n",
    "#     ('atc2d', ((96, 144, (3, 3), 1, 1, 1, 24), 1, None, None, 'relu', True)), \n",
    "#     ('atc2d', ((144, 192, (3, 3), 1, 1, 1, 24), 1, 'first', (2, 2), 'relu', True)), \n",
    "#     ('cnn2d', ((192, 240, (3, 3), 1, 1, 1, 24), 1, None, None, 'relu', False)), \n",
    "#     ('cnn2d', ((240, 240, (3, 3), 1, 0, 1, 24), 1, None, None, False, False)), \n",
    "#     ('adptavgpool', (1, 1)), \n",
    "#     ('linear', (240, 10, (1, 2, 3)))\n",
    "# ]\n",
    "\n",
    "\n",
    "mnist_args.layers=[\n",
    "    ('cnn2d', ((1, 24, (7, 7), 1, 3, 1, 1), 1, None, None, 'relu', False)), \n",
    "    ('cnn2d', ((24, 48, (3, 3), 1, 1, 1, 1), 2, None, None, 'relu', True)), \n",
    "    ('cnn2d', ((48, 96, (3, 3), 1, 1, 1, 1), 2, 'first', (2, 2), 'relu', True)), \n",
    "    ('cnn2d', ((96, 144, (3, 3), 1, 1, 1, 1), 2, None, None, 'relu', True)), \n",
    "    ('cnn2d', ((144, 192, (3, 3), 1, 1, 1, 1), 2, 'first', (2, 2), 'relu', True)), \n",
    "    ('cnn2d', ((192, 240, (3, 3), 1, 1, 1, 1), 1, None, None, 'relu', False)), \n",
    "    ('cnn2d', ((240, 240, (3, 3), 1, 0, 1, 1), 1, None, None, False, False)), \n",
    "    ('adptavgpool', (1, 1)), \n",
    "    ('linear', (240, 10, (1, 2, 3)))\n",
    "]\n",
    "\n",
    "# knpp = [24,48,96,192]\n",
    "# knpp = [30,60,120,240]\n",
    "\n",
    "# mnist_args.layers=[\n",
    "#     ('cnn2d', ((input_channel, knpp[0], (3,3), 1, 1, 1, 1), 1, None, None, activation, False)),\n",
    "#     ('atrc2d', ((knpp[0], knpp[1], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, True)),\n",
    "#     ('atrc2d', ((knpp[1], knpp[2], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, True)),\n",
    "#     ('atrc2d', ((knpp[2], knpp[3], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, True)),\n",
    "#     ('cnn2d', ((knpp[-1], knpp[-1], (3,3), 1, 0, 1, knpp[0]), 1, None, None, activation, False)),\n",
    "#     ('cnn2d', ((knpp[-1], knpp[-1], (3,3), 1, 0, 1, knpp[0]), 1, None, None, False, False)),\n",
    "#     ('adptavgpool', (1,1)),\n",
    "#     ('linear', (knpp[-1], 10, (1,2,3)))\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a240b656",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use: ['cuda:0']\n",
      "add record: 03/15/2023 21:44\n"
     ]
    }
   ],
   "source": [
    "driver = ABC_Driver(mnist_args, None, record_path=None, if_hash=False)\n",
    "# driver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66355dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(driver.model.state_dict(), \"save/MNIST_CNN_2023_03_13.pt\")\n",
    "# driver.model.load_state_dict(torch.load(\"save/MNIST_ABC_2023_02_26.pt\"))\n",
    "driver.model.load_state_dict(torch.load(\"save/MNIST_CNN_2023_02_27.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01969e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.metric(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2598da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoattack import AutoAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71de49ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting parameters for standard version\n"
     ]
    }
   ],
   "source": [
    "adversary = AutoAttack(driver.model, norm='Linf', eps=0.1, version='standard')\n",
    "adversary.attacks_to_run = ['apgd-ce']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0e6ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = driver.data_loader.attack[-1].dataset.data.unsqueeze(1)/255\n",
    "labels = driver.data_loader.attack[-1].dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea47cac9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using standard version including apgd-ce.\n",
      "initial accuracy: 99.68%\n",
      "apgd-ce - 1/100 - 36 out of 100 successfully perturbed\n",
      "apgd-ce - 2/100 - 43 out of 100 successfully perturbed\n",
      "apgd-ce - 3/100 - 42 out of 100 successfully perturbed\n",
      "apgd-ce - 4/100 - 36 out of 100 successfully perturbed\n",
      "apgd-ce - 5/100 - 40 out of 100 successfully perturbed\n",
      "apgd-ce - 6/100 - 38 out of 100 successfully perturbed\n",
      "apgd-ce - 7/100 - 44 out of 100 successfully perturbed\n",
      "apgd-ce - 8/100 - 35 out of 100 successfully perturbed\n",
      "apgd-ce - 9/100 - 35 out of 100 successfully perturbed\n",
      "apgd-ce - 10/100 - 43 out of 100 successfully perturbed\n",
      "apgd-ce - 11/100 - 42 out of 100 successfully perturbed\n",
      "apgd-ce - 12/100 - 43 out of 100 successfully perturbed\n",
      "apgd-ce - 13/100 - 44 out of 100 successfully perturbed\n",
      "apgd-ce - 14/100 - 43 out of 100 successfully perturbed\n",
      "apgd-ce - 15/100 - 39 out of 100 successfully perturbed\n",
      "apgd-ce - 16/100 - 43 out of 100 successfully perturbed\n",
      "apgd-ce - 17/100 - 38 out of 100 successfully perturbed\n",
      "apgd-ce - 18/100 - 37 out of 100 successfully perturbed\n",
      "apgd-ce - 19/100 - 41 out of 100 successfully perturbed\n",
      "apgd-ce - 20/100 - 43 out of 100 successfully perturbed\n",
      "apgd-ce - 21/100 - 41 out of 100 successfully perturbed\n",
      "apgd-ce - 22/100 - 38 out of 100 successfully perturbed\n",
      "apgd-ce - 23/100 - 46 out of 100 successfully perturbed\n",
      "apgd-ce - 24/100 - 44 out of 100 successfully perturbed\n",
      "apgd-ce - 25/100 - 38 out of 100 successfully perturbed\n",
      "apgd-ce - 26/100 - 37 out of 100 successfully perturbed\n",
      "apgd-ce - 27/100 - 36 out of 100 successfully perturbed\n",
      "apgd-ce - 28/100 - 39 out of 100 successfully perturbed\n",
      "apgd-ce - 29/100 - 39 out of 100 successfully perturbed\n",
      "apgd-ce - 30/100 - 40 out of 100 successfully perturbed\n",
      "apgd-ce - 31/100 - 43 out of 100 successfully perturbed\n",
      "apgd-ce - 32/100 - 39 out of 100 successfully perturbed\n",
      "apgd-ce - 33/100 - 34 out of 100 successfully perturbed\n",
      "apgd-ce - 34/100 - 32 out of 100 successfully perturbed\n",
      "apgd-ce - 35/100 - 46 out of 100 successfully perturbed\n",
      "apgd-ce - 36/100 - 47 out of 100 successfully perturbed\n",
      "apgd-ce - 37/100 - 37 out of 100 successfully perturbed\n",
      "apgd-ce - 38/100 - 38 out of 100 successfully perturbed\n",
      "apgd-ce - 39/100 - 33 out of 100 successfully perturbed\n",
      "apgd-ce - 40/100 - 40 out of 100 successfully perturbed\n",
      "apgd-ce - 41/100 - 39 out of 100 successfully perturbed\n",
      "apgd-ce - 42/100 - 48 out of 100 successfully perturbed\n",
      "apgd-ce - 43/100 - 40 out of 100 successfully perturbed\n",
      "apgd-ce - 44/100 - 36 out of 100 successfully perturbed\n",
      "apgd-ce - 45/100 - 38 out of 100 successfully perturbed\n",
      "apgd-ce - 46/100 - 43 out of 100 successfully perturbed\n",
      "apgd-ce - 47/100 - 36 out of 100 successfully perturbed\n",
      "apgd-ce - 48/100 - 45 out of 100 successfully perturbed\n",
      "apgd-ce - 49/100 - 47 out of 100 successfully perturbed\n",
      "apgd-ce - 50/100 - 39 out of 100 successfully perturbed\n",
      "apgd-ce - 51/100 - 25 out of 100 successfully perturbed\n",
      "apgd-ce - 52/100 - 38 out of 100 successfully perturbed\n",
      "apgd-ce - 53/100 - 25 out of 100 successfully perturbed\n",
      "apgd-ce - 54/100 - 21 out of 100 successfully perturbed\n",
      "apgd-ce - 55/100 - 25 out of 100 successfully perturbed\n",
      "apgd-ce - 56/100 - 28 out of 100 successfully perturbed\n",
      "apgd-ce - 57/100 - 37 out of 100 successfully perturbed\n",
      "apgd-ce - 58/100 - 30 out of 100 successfully perturbed\n",
      "apgd-ce - 59/100 - 30 out of 100 successfully perturbed\n",
      "apgd-ce - 60/100 - 37 out of 100 successfully perturbed\n",
      "apgd-ce - 61/100 - 23 out of 100 successfully perturbed\n",
      "apgd-ce - 62/100 - 10 out of 100 successfully perturbed\n",
      "apgd-ce - 63/100 - 15 out of 100 successfully perturbed\n",
      "apgd-ce - 64/100 - 22 out of 100 successfully perturbed\n",
      "apgd-ce - 65/100 - 23 out of 100 successfully perturbed\n",
      "apgd-ce - 66/100 - 62 out of 100 successfully perturbed\n",
      "apgd-ce - 67/100 - 37 out of 100 successfully perturbed\n",
      "apgd-ce - 68/100 - 25 out of 100 successfully perturbed\n",
      "apgd-ce - 69/100 - 33 out of 100 successfully perturbed\n",
      "apgd-ce - 70/100 - 22 out of 100 successfully perturbed\n",
      "apgd-ce - 71/100 - 33 out of 100 successfully perturbed\n",
      "apgd-ce - 72/100 - 35 out of 100 successfully perturbed\n",
      "apgd-ce - 73/100 - 28 out of 100 successfully perturbed\n",
      "apgd-ce - 74/100 - 27 out of 100 successfully perturbed\n",
      "apgd-ce - 75/100 - 41 out of 100 successfully perturbed\n",
      "apgd-ce - 76/100 - 32 out of 100 successfully perturbed\n",
      "apgd-ce - 77/100 - 34 out of 100 successfully perturbed\n",
      "apgd-ce - 78/100 - 11 out of 100 successfully perturbed\n",
      "apgd-ce - 79/100 - 22 out of 100 successfully perturbed\n",
      "apgd-ce - 80/100 - 17 out of 100 successfully perturbed\n",
      "apgd-ce - 81/100 - 28 out of 100 successfully perturbed\n",
      "apgd-ce - 82/100 - 27 out of 100 successfully perturbed\n",
      "apgd-ce - 83/100 - 29 out of 100 successfully perturbed\n",
      "apgd-ce - 84/100 - 28 out of 100 successfully perturbed\n",
      "apgd-ce - 85/100 - 20 out of 100 successfully perturbed\n",
      "apgd-ce - 86/100 - 24 out of 100 successfully perturbed\n",
      "apgd-ce - 87/100 - 21 out of 100 successfully perturbed\n",
      "apgd-ce - 88/100 - 20 out of 100 successfully perturbed\n",
      "apgd-ce - 89/100 - 23 out of 100 successfully perturbed\n",
      "apgd-ce - 90/100 - 27 out of 100 successfully perturbed\n",
      "apgd-ce - 91/100 - 11 out of 100 successfully perturbed\n",
      "apgd-ce - 92/100 - 15 out of 100 successfully perturbed\n",
      "apgd-ce - 93/100 - 31 out of 100 successfully perturbed\n",
      "apgd-ce - 94/100 - 35 out of 100 successfully perturbed\n",
      "apgd-ce - 95/100 - 28 out of 100 successfully perturbed\n",
      "apgd-ce - 96/100 - 33 out of 100 successfully perturbed\n",
      "apgd-ce - 97/100 - 53 out of 100 successfully perturbed\n",
      "apgd-ce - 98/100 - 44 out of 100 successfully perturbed\n",
      "apgd-ce - 99/100 - 63 out of 100 successfully perturbed\n",
      "apgd-ce - 100/100 - 27 out of 68 successfully perturbed\n",
      "robust accuracy after APGD-CE: 65.30% (total time 324.7 s)\n",
      "max Linf perturbation: 0.10000, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
      "robust accuracy: 65.30%\n"
     ]
    }
   ],
   "source": [
    "x_adv, y_adv = adversary.run_standard_evaluation(images, labels, bs=100, return_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ec596b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 28, 28])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_adv.mean(dim=1, keepdim=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78317fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_adv.mean(dim=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ca9c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09c9bea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.653"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels, y_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfb71a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_adv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "605aec3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_adv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5885b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torchvision.transforms.Normalize((0.1307,), (0.3081,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c2fdcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.4242)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t(x_adv).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33e67399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f23fd7b0e20>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.utils.data.DataLoader(driver.data_loader.attack[-1].dataset, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60ccc663",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torchvision.transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "282a8bdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_adv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/mfeng/anaconda/envs/atd2022/lib/python3.9/site-packages/torchvision/transforms/transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/mfeng/anaconda/envs/atd2022/lib/python3.9/site-packages/torchvision/transforms/functional.py:137\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m     _log_api_usage_once(to_tensor)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (F_pil\u001b[38;5;241m.\u001b[39m_is_pil_image(pic) \u001b[38;5;129;01mor\u001b[39;00m _is_numpy(pic)):\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should be PIL Image or ndarray. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(pic)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy(pic) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_numpy_image(pic):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should be 2/3 dimensional. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpic\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>"
     ]
    }
   ],
   "source": [
    "t(x_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoattack apgd-ce:\n",
    "cnn: 0.6552\n",
    "abc: 0.8547"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf38e823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28c51bc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean    0.9971\n",
       "fgsm     0.8913\n",
       "pgd      0.2877\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.metric(test_attack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbd0a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.model.parameters():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb419ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31518ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
