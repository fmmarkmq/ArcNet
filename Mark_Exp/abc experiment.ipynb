{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.tools import dotdict\n",
    "from driver.driver import ABC_Driver\n",
    "from torch_geometric_temporal import METRLADatasetLoader\n",
    "from other_model.other_model import make_default_model\n",
    "import atd2022\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.set_device(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "atd_args = dotdict()\n",
    "\n",
    "atd_args.name = 'atd'\n",
    "atd_args.train_batch_size = 25\n",
    "atd_args.predict_len = 4\n",
    "atd_args.history_len = 7\n",
    "\n",
    "atd_args.train_epochs= 10\n",
    "atd_args.lr = 0.00009\n",
    "atd_args.criterion = 'L1'\n",
    "atd_args.scheduler = None\n",
    "\n",
    "activation = 'relu'\n",
    "pool_name = 'avg'\n",
    "input_channel = 1\n",
    "pixel_number = atd_args.history_len*5200\n",
    "kernel_size = 6\n",
    "knpp = 12\n",
    "knpp2 = atd_args.predict_len\n",
    "\n",
    "atd_args.layers=[\n",
    "    ('agnostic', ((input_channel, knpp, kernel_size), 1, None, None, activation)),\n",
    "    ('agnostic', ((knpp, knpp2, kernel_size), 1, None, None, activation)),\n",
    "    ('linear', (knpp2*atd_args.history_len, atd_args.predict_len, (1,2), 1, (1, atd_args.predict_len))),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_args = dotdict()\n",
    "\n",
    "wt_args.name = 'wiki_traffic'\n",
    "wt_args.train_batch_size = 30\n",
    "wt_args.predict_len = 1\n",
    "wt_args.history_len = 5\n",
    "\n",
    "wt_args.train_epochs= 10\n",
    "wt_args.lr = 0.001\n",
    "wt_args.criterion = 'L1'\n",
    "wt_args.scheduler = None\n",
    "\n",
    "activation = 'relu'\n",
    "pool_name = 'avg'\n",
    "input_channel = 1\n",
    "pixel_number = wt_args.history_len*1400\n",
    "kernel_size = 3\n",
    "knpp = 5\n",
    "knpp2 = 15\n",
    "\n",
    "wt_args.layers=[\n",
    "    ('specific', ((input_channel, knpp, kernel_size), 1, None, None, activation)),\n",
    "    ('specific', ((knpp, knpp2, kernel_size), 1, None, None, activation)),\n",
    "    ('linear', (knpp2*wt_args.history_len, wt_args.predict_len, (1,2), 1, (1, wt_args.predict_len))),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_args = dotdict()\n",
    "\n",
    "lat_args.name = 'lat'\n",
    "lat_args.train_batch_size = 30\n",
    "lat_args.predict_len = 1\n",
    "lat_args.history_len = 5\n",
    "\n",
    "lat_args.train_epochs= 10\n",
    "lat_args.lr = 0.001\n",
    "lat_args.criterion = 'L1'\n",
    "lat_args.scheduler = None\n",
    "\n",
    "activation = 'relu'\n",
    "pool_name = 'avg'\n",
    "input_channel = 1\n",
    "pixel_number = lat_args.history_len*207\n",
    "kernel_size = 3\n",
    "knpp = 5\n",
    "knpp2 = 15\n",
    "\n",
    "lat_args.layers=[\n",
    "    ('specific', ((input_channel, knpp, kernel_size), 1, None, None, activation)),\n",
    "    ('specific', ((knpp, knpp2, kernel_size), 1, None, None, activation)),\n",
    "    ('linear', (knpp2*lat_args.history_len, lat_args.predict_len, (1,2), 1, (1, lat_args.predict_len))),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_args = dotdict()\n",
    "\n",
    "mnist_args.name = 'mnist'\n",
    "mnist_args.train_batch_size = 120\n",
    "mnist_args.predict_batch_size = 100\n",
    "\n",
    "\n",
    "mnist_args.train_epochs = 30\n",
    "mnist_args.lr = 0.001\n",
    "mnist_args.criterion = 'CE'\n",
    "mnist_args.optimizer = 'Adam'\n",
    "mnist_args.scheduler = 'multistep3'\n",
    "mnist_args.attack = {'fgsm':(0.1,), 'pgd':(0.1,0.1,20)}\n",
    "\n",
    "activation = 'relu'\n",
    "input_channel = 1\n",
    "knpp = [30,60,120,180,240]\n",
    "\n",
    "mnist_args.layers=[\n",
    "    ('cnn2d', ((input_channel, knpp[0], (7,7), 1, 3, 1, 1), 1, None, None, activation, False)),\n",
    "    ('atc2d', ((knpp[0], knpp[1], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, True)),\n",
    "    ('atc2d', ((knpp[1], knpp[2], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, True)),\n",
    "    ('atc2d', ((knpp[2], knpp[3], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, True)),\n",
    "    ('atc2d', ((knpp[3], knpp[4], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, True)),\n",
    "    ('cnn2d', ((knpp[-1], knpp[-1], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, False)),\n",
    "    ('cnn2d', ((knpp[-1], knpp[-1], (3,3), 1, 0, 1, knpp[0]), 1, None, None, False, False)),\n",
    "    ('adptavgpool', (1,1)),\n",
    "    ('linear', (knpp[-1], 10, (1,2,3))),\n",
    "    ('softmax', (1))\n",
    "]\n",
    "\n",
    "# knpp = [24,48,96,192]\n",
    "# # knpp = [30,60,120,240]\n",
    "\n",
    "# mnist_args.layers=[\n",
    "#     ('cnn2d', ((input_channel, knpp[0], (3,3), 1, 1, 1, 1), 1, None, None, activation, False)),\n",
    "#     ('atc2d', ((knpp[0], knpp[1], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, True)),\n",
    "#     ('atc2d', ((knpp[1], knpp[2], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, True)),\n",
    "#     ('atc2d', ((knpp[2], knpp[3], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, True)),\n",
    "#     ('cnn2d', ((knpp[-1], knpp[-1], (3,3), 1, 0, 1, knpp[0]), 1, None, None, activation, False)),\n",
    "#     ('cnn2d', ((knpp[-1], knpp[-1], (3,3), 1, 0, 1, knpp[0]), 1, None, None, False, False)),\n",
    "#     ('adptavgpool', (1,1)),\n",
    "#     ('linear', (knpp[-1], 10, (1,2,3))),\n",
    "#     ('softmax', (1))\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_args = dotdict()\n",
    "\n",
    "cifar10_args.name = 'cifar10'\n",
    "cifar10_args.device = ['cuda:4', 'cuda:5']\n",
    "cifar10_args.train_batch_size = 100\n",
    "cifar10_args.predict_batch_size = 100\n",
    "\n",
    "cifar10_args.train_epochs = 250\n",
    "cifar10_args.lr = 0.01\n",
    "cifar10_args.criterion = 'CE'\n",
    "cifar10_args.optimizer = 'AdamW'\n",
    "cifar10_args.scheduler = 'OneCycle'\n",
    "cifar10_args.attack = {'fgsm':(0.005,), 'pgd':(0.005,0.1,20)}\n",
    "\n",
    "activation = 'relu'\n",
    "input_channel = 3\n",
    "# knpp = [40,80,160,240,320]\n",
    "\n",
    "# cifar10_args.layers=[\n",
    "#     ('cnn2d', ((input_channel, knpp[0], (3,3), 1, 1, 1, 1), 1, None, None, activation, False)),\n",
    "#     ('atc2d', ((knpp[0], knpp[1], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, True)),\n",
    "#     ('atc2d', ((knpp[1], knpp[2], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, True)),\n",
    "#     ('atc2d', ((knpp[2], knpp[3], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, True)),\n",
    "#     ('atc2d', ((knpp[3], knpp[4], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, True)),\n",
    "#     ('cnn2d', ((knpp[-1], knpp[-1], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, False)),\n",
    "#     ('cnn2d', ((knpp[-1], knpp[-1], (3,3), 1, 0, 1, knpp[0]), 1, None, None, False, False)),\n",
    "#     ('adptavgpool', (1,1)),\n",
    "#     ('linear', (knpp[-1], 10, (1,2,3))),\n",
    "#     ('softmax', (1))\n",
    "# ]\n",
    "\n",
    "# resnet\n",
    "# cifar10_args.layers=[\n",
    "#     ('cnn2d', ((3, 16, (3, 3), 1, 1), 1, None, None, 'relu', False)), \n",
    "#     ('cnn2d', ((16, 16, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    "#     ('cnn2d', ((16, 16, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    "#     ('cnn2d', ((16, 16, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    "#     ('cnn2d', ((16, 32, (3, 3), 1, 1), 2, 'first', (2, 2), 'relu')), \n",
    "#     ('cnn2d', ((32, 32, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    "#     ('cnn2d', ((32, 32, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    "#     ('cnn2d', ((32, 64, (3, 3), 1, 1), 2, 'first', (2, 2), 'relu')), \n",
    "#     ('cnn2d', ((64, 64, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    "#     ('cnn2d', ((64, 64, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    "#     ('adptavgpool', (1, 1)), \n",
    "#     ('linear', (64, 10, (1, 2, 3))), \n",
    "#     ('softmax', 1)\n",
    "# ]\n",
    "\n",
    "# abccnn\n",
    "# knpp = [32,64,96,128,160,192,224]\n",
    "# cifar10_args.layers=[\n",
    "#     ('cnn2d', ((input_channel, knpp[0], (3,3), 1, 1, 1, 1), 1, None, None, activation, False)),\n",
    "#     ('cnn2d', ((knpp[0], knpp[1], (3,3), 1, 1, 1, 1), 2, None, None, activation, True)),\n",
    "#     ('cnn2d', ((knpp[1], knpp[2], (3,3), 1, 1, 1, 1), 2, 'first', (2,2), activation, True)),\n",
    "#     ('cnn2d', ((knpp[2], knpp[3], (3,3), 1, 1, 1, 1), 2, None, None, activation, True)),\n",
    "#     ('cnn2d', ((knpp[3], knpp[4], (3,3), 1, 1, 1, 1), 2, 'first', (2,2), activation, True)),\n",
    "#     ('cnn2d', ((knpp[4], knpp[5], (3,3), 1, 1, 1, 1), 2, None, None, activation, True)),\n",
    "#     ('cnn2d', ((knpp[5], knpp[6], (3,3), 1, 1, 1, 1), 2, 'first', (2,2), activation, True)),\n",
    "#     ('cnn2d', ((knpp[-1], knpp[-1], (3,3), 1, 0, 1, 1), 1, None, None, activation, False)),\n",
    "#     ('cnn2d', ((knpp[-1], knpp[-1], (2,2), 1, 0, 1, 1), 1, None, None, False, False)),\n",
    "# #     ('adptavgpool', (1,1)),\n",
    "#     ('linear', (knpp[-1], 10, (1,2,3))),\n",
    "#     ('softmax', (1))\n",
    "# ]\n",
    "\n",
    "\n",
    "knpp = [48,96,144,240,336,432,528,624]\n",
    "\n",
    "cifar10_args.layers=[\n",
    "    ('cnn2d', ((input_channel, knpp[0], (3,3), 1, 1, 1, 1), 1, None, None, activation, False)),\n",
    "    ('atrc2d', ((knpp[0], knpp[1], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, False)),\n",
    "    ('atrc2d', ((knpp[1], knpp[2], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, False)),\n",
    "    ('atrc2d', ((knpp[2], knpp[3], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, False)),\n",
    "    ('atrc2d', ((knpp[3], knpp[4], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, False)),\n",
    "    ('atrc2d', ((knpp[4], knpp[5], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, False)),\n",
    "    ('atrc2d', ((knpp[5], knpp[6], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, False)),\n",
    "    ('atrc2d', ((knpp[6], knpp[7], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, False)),\n",
    "    ('adptavgpool', (1,1)),\n",
    "    ('linear', (knpp[-1], 10, (1,2,3)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.arange(1,10)*48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use: ['cuda:4', 'cuda:5']\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "add record: 03/26/2023 09:48\n",
      "epoch: 0, train_loss: 1.7715, test_metric: 0.5299, time: 640.1170034408569\n",
      "epoch: 1, train_loss: 1.4424, test_metric: 0.6315, time: 637.0665020942688\n",
      "epoch: 2, train_loss: 1.2745, test_metric: 0.6749, time: 636.9777297973633\n",
      "epoch: 3, train_loss: 1.1583, test_metric: 0.7091, time: 637.0282580852509\n",
      "epoch: 4, train_loss: 1.0692, test_metric: 0.7112, time: 636.8239636421204\n",
      "epoch: 5, train_loss: 1.0016, test_metric: 0.7649, time: 637.0339353084564\n",
      "epoch: 6, train_loss: 0.9575, test_metric: 0.7776, time: 637.1081812381744\n",
      "epoch: 7, train_loss: 0.9159, test_metric: 0.7787, time: 637.2223207950592\n",
      "epoch: 8, train_loss: 0.88, test_metric: 0.7857, time: 636.9696855545044\n",
      "epoch: 9, train_loss: 0.8496, test_metric: 0.8027, time: 637.4048428535461\n",
      "epoch: 10, train_loss: 0.828, test_metric: 0.8049, time: 637.2197160720825\n",
      "epoch: 11, train_loss: 0.7996, test_metric: 0.8226, time: 637.2537338733673\n",
      "epoch: 12, train_loss: 0.7783, test_metric: 0.7983, time: 637.1691238880157\n",
      "epoch: 13, train_loss: 0.7655, test_metric: 0.8257, time: 637.3979279994965\n",
      "epoch: 14, train_loss: 0.756, test_metric: 0.8256, time: 637.2288846969604\n",
      "epoch: 15, train_loss: 0.7358, test_metric: 0.8181, time: 637.1765933036804\n",
      "epoch: 16, train_loss: 0.7091, test_metric: 0.8257, time: 637.1721696853638\n",
      "epoch: 17, train_loss: 0.6995, test_metric: 0.8406, time: 637.1441085338593\n",
      "epoch: 18, train_loss: 0.6757, test_metric: 0.8461, time: 636.9318451881409\n",
      "epoch: 19, train_loss: 0.6695, test_metric: 0.8484, time: 637.0961353778839\n",
      "epoch: 20, train_loss: 0.6494, test_metric: 0.8263, time: 637.0738430023193\n",
      "epoch: 21, train_loss: 0.6414, test_metric: 0.8453, time: 637.1627585887909\n",
      "epoch: 22, train_loss: 0.6266, test_metric: 0.8707, time: 637.2230048179626\n",
      "epoch: 23, train_loss: 0.6115, test_metric: 0.8698, time: 637.1811740398407\n"
     ]
    }
   ],
   "source": [
    "args = cifar10_args\n",
    "data = None\n",
    "# data = atd2022.io.read_csv()\n",
    "# data = pd.read_csv('/scratch/mfeng/data/ABC/Wiki_Traffic/filled_selected_train_1.csv', index_col=0, header=[0,1,2,3], parse_dates=True)\n",
    "# data = pd.read_csv('/scratch/mfeng/data/ABC/LA_Traffic/LA_Traffic.csv', index_col=0)\n",
    "# data = data.head(200)\n",
    "\n",
    "driver = ABC_Driver(args, data, record_path=None, if_hash=False)\n",
    "driver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use: ['cuda:4', 'cuda:5']\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "add record: 03/21/2023 11:04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/mfeng/anaconda/envs/atd2022/lib/python3.9/site-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /opt/conda/conda-bld/pytorch_1670525539683/work/aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 2.0763, test_metric: 0.413, time: 289.0976550579071\n",
      "epoch: 1, train_loss: 1.884, test_metric: 0.5155, time: 288.3746621608734\n",
      "epoch: 2, train_loss: 1.7553, test_metric: 0.5697, time: 288.291672706604\n",
      "epoch: 3, train_loss: 1.6458, test_metric: 0.6063, time: 288.28107476234436\n",
      "epoch: 4, train_loss: 1.5531, test_metric: 0.6638, time: 288.22270011901855\n",
      "epoch: 5, train_loss: 1.4642, test_metric: 0.6931, time: 288.1883018016815\n",
      "epoch: 6, train_loss: 1.3969, test_metric: 0.703, time: 288.2314326763153\n",
      "epoch: 7, train_loss: 1.315, test_metric: 0.735, time: 288.2426607608795\n",
      "epoch: 8, train_loss: 1.2554, test_metric: 0.7478, time: 288.2106845378876\n",
      "epoch: 9, train_loss: 1.2057, test_metric: 0.7549, time: 288.1534719467163\n",
      "epoch: 10, train_loss: 1.1694, test_metric: 0.7699, time: 288.209885597229\n",
      "epoch: 11, train_loss: 1.1257, test_metric: 0.7825, time: 288.2334530353546\n",
      "epoch: 12, train_loss: 1.0954, test_metric: 0.7712, time: 288.1428027153015\n",
      "epoch: 13, train_loss: 1.0679, test_metric: 0.8071, time: 288.2595510482788\n",
      "epoch: 14, train_loss: 1.0442, test_metric: 0.8045, time: 288.2302222251892\n",
      "epoch: 15, train_loss: 1.0138, test_metric: 0.8227, time: 288.2739431858063\n",
      "epoch: 16, train_loss: 1.0015, test_metric: 0.8224, time: 288.2482855319977\n",
      "epoch: 17, train_loss: 0.9767, test_metric: 0.823, time: 288.2133846282959\n",
      "epoch: 18, train_loss: 0.9538, test_metric: 0.8236, time: 288.2361900806427\n",
      "epoch: 19, train_loss: 0.9462, test_metric: 0.8283, time: 288.22604274749756\n",
      "epoch: 20, train_loss: 0.9308, test_metric: 0.8419, time: 288.27385783195496\n",
      "epoch: 21, train_loss: 0.9167, test_metric: 0.8156, time: 288.22779655456543\n",
      "epoch: 22, train_loss: 0.8974, test_metric: 0.8426, time: 288.2211740016937\n",
      "epoch: 23, train_loss: 0.8906, test_metric: 0.85, time: 288.18903064727783\n",
      "epoch: 24, train_loss: 0.8827, test_metric: 0.8567, time: 288.2496693134308\n",
      "epoch: 25, train_loss: 0.8646, test_metric: 0.8498, time: 288.3099117279053\n",
      "epoch: 26, train_loss: 0.8496, test_metric: 0.8465, time: 288.32052063941956\n",
      "epoch: 27, train_loss: 0.841, test_metric: 0.8449, time: 288.32496213912964\n",
      "epoch: 28, train_loss: 0.8229, test_metric: 0.8543, time: 288.3690412044525\n",
      "epoch: 29, train_loss: 0.8148, test_metric: 0.8655, time: 288.5613896846771\n",
      "epoch: 30, train_loss: 0.8034, test_metric: 0.8661, time: 288.3895950317383\n",
      "epoch: 31, train_loss: 0.7923, test_metric: 0.8755, time: 288.39111852645874\n",
      "epoch: 32, train_loss: 0.7771, test_metric: 0.8745, time: 288.26689076423645\n",
      "epoch: 33, train_loss: 0.7608, test_metric: 0.8652, time: 288.3087751865387\n",
      "epoch: 34, train_loss: 0.7562, test_metric: 0.8778, time: 288.30701184272766\n",
      "epoch: 35, train_loss: 0.7398, test_metric: 0.8842, time: 288.3172836303711\n",
      "epoch: 36, train_loss: 0.7292, test_metric: 0.8901, time: 288.24800181388855\n",
      "epoch: 37, train_loss: 0.7139, test_metric: 0.8761, time: 288.2211422920227\n",
      "epoch: 38, train_loss: 0.7091, test_metric: 0.8789, time: 288.27053022384644\n",
      "epoch: 39, train_loss: 0.6981, test_metric: 0.8875, time: 288.19914650917053\n",
      "epoch: 40, train_loss: 0.692, test_metric: 0.8919, time: 288.2883040904999\n",
      "epoch: 41, train_loss: 0.6797, test_metric: 0.894, time: 288.32058358192444\n",
      "epoch: 42, train_loss: 0.6698, test_metric: 0.8945, time: 288.3989772796631\n",
      "epoch: 43, train_loss: 0.6665, test_metric: 0.9018, time: 288.26113390922546\n",
      "epoch: 44, train_loss: 0.6607, test_metric: 0.8897, time: 288.2794711589813\n",
      "epoch: 45, train_loss: 0.6515, test_metric: 0.8912, time: 288.243460893631\n",
      "epoch: 46, train_loss: 0.6477, test_metric: 0.8951, time: 288.2972524166107\n",
      "epoch: 47, train_loss: 0.6415, test_metric: 0.9024, time: 288.3206396102905\n",
      "epoch: 48, train_loss: 0.6335, test_metric: 0.9017, time: 288.29401993751526\n",
      "epoch: 49, train_loss: 0.6245, test_metric: 0.9053, time: 288.30084466934204\n",
      "epoch: 50, train_loss: 0.6308, test_metric: 0.9123, time: 288.3118529319763\n",
      "epoch: 51, train_loss: 0.6141, test_metric: 0.9111, time: 288.287962436676\n",
      "epoch: 52, train_loss: 0.6051, test_metric: 0.8991, time: 288.1636073589325\n",
      "epoch: 53, train_loss: 0.6021, test_metric: 0.909, time: 288.27449226379395\n",
      "epoch: 54, train_loss: 0.6014, test_metric: 0.9072, time: 288.25712060928345\n",
      "epoch: 55, train_loss: 0.586, test_metric: 0.915, time: 288.2177848815918\n",
      "epoch: 56, train_loss: 0.584, test_metric: 0.9088, time: 288.23843026161194\n",
      "epoch: 57, train_loss: 0.5832, test_metric: 0.9091, time: 288.2751896381378\n",
      "epoch: 58, train_loss: 0.5809, test_metric: 0.9131, time: 288.2362153530121\n",
      "epoch: 59, train_loss: 0.5696, test_metric: 0.9138, time: 288.2721426486969\n",
      "epoch: 60, train_loss: 0.5637, test_metric: 0.9118, time: 288.3195552825928\n",
      "epoch: 61, train_loss: 0.5597, test_metric: 0.9166, time: 288.27667593955994\n",
      "epoch: 62, train_loss: 0.5532, test_metric: 0.92, time: 288.25524711608887\n",
      "epoch: 63, train_loss: 0.5521, test_metric: 0.9157, time: 288.1823613643646\n",
      "epoch: 64, train_loss: 0.5475, test_metric: 0.9188, time: 288.1651895046234\n",
      "epoch: 65, train_loss: 0.5442, test_metric: 0.918, time: 288.2489745616913\n",
      "epoch: 66, train_loss: 0.5397, test_metric: 0.9147, time: 288.200865983963\n",
      "epoch: 67, train_loss: 0.531, test_metric: 0.9148, time: 288.07191729545593\n",
      "epoch: 68, train_loss: 0.5275, test_metric: 0.927, time: 288.041561126709\n",
      "epoch: 69, train_loss: 0.5239, test_metric: 0.9268, time: 288.0864679813385\n",
      "epoch: 70, train_loss: 0.5155, test_metric: 0.9239, time: 288.13432455062866\n",
      "epoch: 71, train_loss: 0.5058, test_metric: 0.9217, time: 288.16556549072266\n",
      "epoch: 72, train_loss: 0.5131, test_metric: 0.9223, time: 288.1382818222046\n",
      "epoch: 73, train_loss: 0.5006, test_metric: 0.9212, time: 288.1199688911438\n",
      "epoch: 74, train_loss: 0.4985, test_metric: 0.9251, time: 288.18038511276245\n",
      "epoch: 75, train_loss: 0.4943, test_metric: 0.9236, time: 288.1738841533661\n",
      "epoch: 76, train_loss: 0.4847, test_metric: 0.9315, time: 288.2108657360077\n",
      "epoch: 77, train_loss: 0.4856, test_metric: 0.9274, time: 288.16653990745544\n",
      "epoch: 78, train_loss: 0.4801, test_metric: 0.9295, time: 288.2318363189697\n",
      "epoch: 79, train_loss: 0.4749, test_metric: 0.9259, time: 288.13187766075134\n",
      "epoch: 80, train_loss: 0.477, test_metric: 0.9334, time: 288.1642577648163\n",
      "epoch: 81, train_loss: 0.4724, test_metric: 0.9279, time: 288.2512888908386\n",
      "epoch: 82, train_loss: 0.4697, test_metric: 0.9356, time: 288.19871187210083\n",
      "epoch: 83, train_loss: 0.4615, test_metric: 0.9308, time: 288.1373281478882\n",
      "epoch: 84, train_loss: 0.457, test_metric: 0.9337, time: 288.0375120639801\n",
      "epoch: 85, train_loss: 0.4581, test_metric: 0.9292, time: 288.04034447669983\n",
      "epoch: 86, train_loss: 0.4523, test_metric: 0.9353, time: 288.1179428100586\n",
      "epoch: 87, train_loss: 0.4454, test_metric: 0.9368, time: 288.1324758529663\n",
      "epoch: 88, train_loss: 0.4407, test_metric: 0.9355, time: 288.0701861381531\n",
      "epoch: 89, train_loss: 0.4415, test_metric: 0.9372, time: 288.0182421207428\n",
      "epoch: 90, train_loss: 0.4393, test_metric: 0.9351, time: 288.06908559799194\n",
      "epoch: 91, train_loss: 0.4346, test_metric: 0.9373, time: 288.0108187198639\n",
      "epoch: 92, train_loss: 0.4306, test_metric: 0.9431, time: 288.1072647571564\n",
      "epoch: 93, train_loss: 0.4262, test_metric: 0.9377, time: 288.14171409606934\n",
      "epoch: 94, train_loss: 0.4256, test_metric: 0.9361, time: 288.10882782936096\n",
      "epoch: 95, train_loss: 0.4233, test_metric: 0.9341, time: 288.02226972579956\n",
      "epoch: 96, train_loss: 0.4206, test_metric: 0.9421, time: 288.02879214286804\n",
      "epoch: 97, train_loss: 0.4231, test_metric: 0.9371, time: 288.00650429725647\n",
      "epoch: 98, train_loss: 0.4133, test_metric: 0.9407, time: 287.9808270931244\n",
      "epoch: 99, train_loss: 0.4105, test_metric: 0.9386, time: 287.95658135414124\n",
      "epoch: 100, train_loss: 0.4106, test_metric: 0.9413, time: 288.0068006515503\n",
      "epoch: 101, train_loss: 0.4057, test_metric: 0.9321, time: 288.0161335468292\n",
      "epoch: 102, train_loss: 0.4018, test_metric: 0.9379, time: 287.9508857727051\n",
      "epoch: 103, train_loss: 0.3981, test_metric: 0.9412, time: 287.95774126052856\n",
      "epoch: 104, train_loss: 0.399, test_metric: 0.9442, time: 287.96870946884155\n",
      "epoch: 105, train_loss: 0.3889, test_metric: 0.9443, time: 288.00709533691406\n",
      "epoch: 106, train_loss: 0.3926, test_metric: 0.9422, time: 288.0323793888092\n",
      "epoch: 107, train_loss: 0.3891, test_metric: 0.9392, time: 287.9857771396637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 108, train_loss: 0.3777, test_metric: 0.9412, time: 287.9883668422699\n",
      "epoch: 109, train_loss: 0.3887, test_metric: 0.9437, time: 287.950807094574\n",
      "epoch: 110, train_loss: 0.3817, test_metric: 0.943, time: 287.8674190044403\n",
      "epoch: 111, train_loss: 0.379, test_metric: 0.9447, time: 287.7202353477478\n",
      "epoch: 112, train_loss: 0.3799, test_metric: 0.946, time: 287.66538071632385\n",
      "epoch: 113, train_loss: 0.3789, test_metric: 0.9443, time: 287.76473593711853\n",
      "epoch: 114, train_loss: 0.3664, test_metric: 0.9436, time: 287.71680641174316\n",
      "epoch: 115, train_loss: 0.3766, test_metric: 0.9458, time: 288.0416684150696\n",
      "epoch: 116, train_loss: 0.3668, test_metric: 0.9424, time: 287.70735359191895\n",
      "epoch: 117, train_loss: 0.3637, test_metric: 0.9414, time: 287.7299499511719\n",
      "epoch: 118, train_loss: 0.3617, test_metric: 0.9441, time: 287.80285120010376\n",
      "epoch: 119, train_loss: 0.3569, test_metric: 0.9471, time: 287.7107663154602\n",
      "epoch: 120, train_loss: 0.3536, test_metric: 0.946, time: 287.7586705684662\n",
      "epoch: 121, train_loss: 0.3536, test_metric: 0.9428, time: 287.7526400089264\n",
      "epoch: 122, train_loss: 0.3562, test_metric: 0.9473, time: 287.6948313713074\n",
      "epoch: 123, train_loss: 0.3486, test_metric: 0.9446, time: 287.7313902378082\n",
      "epoch: 124, train_loss: 0.3483, test_metric: 0.9499, time: 287.6439108848572\n",
      "epoch: 125, train_loss: 0.3492, test_metric: 0.9472, time: 287.63366985321045\n",
      "epoch: 126, train_loss: 0.341, test_metric: 0.9478, time: 287.72684597969055\n",
      "epoch: 127, train_loss: 0.3468, test_metric: 0.9469, time: 288.03772377967834\n",
      "epoch: 128, train_loss: 0.3383, test_metric: 0.9487, time: 287.91030979156494\n",
      "epoch: 129, train_loss: 0.3348, test_metric: 0.9503, time: 287.9486873149872\n",
      "epoch: 130, train_loss: 0.327, test_metric: 0.9482, time: 287.92047142982483\n",
      "epoch: 131, train_loss: 0.3381, test_metric: 0.9516, time: 287.87889337539673\n",
      "epoch: 132, train_loss: 0.3293, test_metric: 0.95, time: 287.87945556640625\n",
      "epoch: 133, train_loss: 0.3294, test_metric: 0.9435, time: 287.7725315093994\n",
      "epoch: 134, train_loss: 0.3249, test_metric: 0.9502, time: 287.7858200073242\n",
      "epoch: 135, train_loss: 0.3218, test_metric: 0.9492, time: 287.89188742637634\n",
      "epoch: 136, train_loss: 0.3238, test_metric: 0.9492, time: 287.83128094673157\n",
      "epoch: 137, train_loss: 0.3246, test_metric: 0.9504, time: 288.0168106555939\n",
      "epoch: 138, train_loss: 0.3177, test_metric: 0.9511, time: 287.74927616119385\n",
      "epoch: 139, train_loss: 0.3178, test_metric: 0.9515, time: 287.6645154953003\n",
      "epoch: 140, train_loss: 0.3179, test_metric: 0.9514, time: 287.85291290283203\n",
      "epoch: 141, train_loss: 0.3067, test_metric: 0.949, time: 287.9556050300598\n",
      "epoch: 142, train_loss: 0.3136, test_metric: 0.9508, time: 287.9731206893921\n",
      "epoch: 143, train_loss: 0.3139, test_metric: 0.9467, time: 287.7923831939697\n",
      "epoch: 144, train_loss: 0.31, test_metric: 0.9507, time: 287.80800437927246\n",
      "epoch: 145, train_loss: 0.3026, test_metric: 0.9537, time: 287.7541620731354\n",
      "epoch: 146, train_loss: 0.3039, test_metric: 0.9502, time: 287.790146112442\n",
      "epoch: 147, train_loss: 0.2981, test_metric: 0.9546, time: 287.8065390586853\n",
      "epoch: 148, train_loss: 0.3058, test_metric: 0.951, time: 287.7224895954132\n",
      "epoch: 149, train_loss: 0.3007, test_metric: 0.9508, time: 287.80469369888306\n",
      "epoch: 150, train_loss: 0.295, test_metric: 0.9531, time: 287.795040845871\n",
      "epoch: 151, train_loss: 0.2948, test_metric: 0.9558, time: 287.7594702243805\n",
      "epoch: 152, train_loss: 0.2877, test_metric: 0.9525, time: 288.01103019714355\n",
      "epoch: 153, train_loss: 0.2894, test_metric: 0.9542, time: 287.76588010787964\n",
      "epoch: 154, train_loss: 0.2921, test_metric: 0.955, time: 287.79421520233154\n",
      "epoch: 155, train_loss: 0.2876, test_metric: 0.9547, time: 287.74157905578613\n",
      "epoch: 156, train_loss: 0.2824, test_metric: 0.9512, time: 287.70202374458313\n",
      "epoch: 157, train_loss: 0.2857, test_metric: 0.9524, time: 287.883109331131\n",
      "epoch: 158, train_loss: 0.2783, test_metric: 0.9525, time: 288.15300154685974\n",
      "epoch: 159, train_loss: 0.2809, test_metric: 0.9541, time: 287.9093954563141\n",
      "epoch: 160, train_loss: 0.2756, test_metric: 0.9545, time: 287.84851908683777\n",
      "epoch: 161, train_loss: 0.2736, test_metric: 0.9536, time: 287.7369689941406\n",
      "epoch: 162, train_loss: 0.2765, test_metric: 0.9528, time: 287.82773900032043\n",
      "epoch: 163, train_loss: 0.2771, test_metric: 0.9549, time: 287.7965018749237\n",
      "epoch: 164, train_loss: 0.2706, test_metric: 0.9532, time: 287.77197337150574\n",
      "epoch: 165, train_loss: 0.2707, test_metric: 0.9548, time: 287.70590806007385\n",
      "epoch: 166, train_loss: 0.2643, test_metric: 0.9549, time: 287.74323749542236\n",
      "epoch: 167, train_loss: 0.2675, test_metric: 0.9517, time: 287.75205516815186\n",
      "epoch: 168, train_loss: 0.2669, test_metric: 0.9532, time: 287.6908211708069\n",
      "epoch: 169, train_loss: 0.2593, test_metric: 0.9546, time: 287.68485593795776\n",
      "epoch: 170, train_loss: 0.257, test_metric: 0.9549, time: 287.7477865219116\n",
      "epoch: 171, train_loss: 0.263, test_metric: 0.9554, time: 287.74973011016846\n",
      "epoch: 172, train_loss: 0.2587, test_metric: 0.9565, time: 287.7198221683502\n",
      "epoch: 173, train_loss: 0.2545, test_metric: 0.9563, time: 287.7784414291382\n",
      "epoch: 174, train_loss: 0.2571, test_metric: 0.9548, time: 287.9708957672119\n",
      "epoch: 175, train_loss: 0.2511, test_metric: 0.9573, time: 287.68203926086426\n",
      "epoch: 176, train_loss: 0.2551, test_metric: 0.9568, time: 287.7079019546509\n",
      "epoch: 177, train_loss: 0.2454, test_metric: 0.9552, time: 287.75793409347534\n",
      "epoch: 178, train_loss: 0.2476, test_metric: 0.9555, time: 287.7798373699188\n",
      "epoch: 179, train_loss: 0.2451, test_metric: 0.9539, time: 287.8487377166748\n",
      "epoch: 180, train_loss: 0.2492, test_metric: 0.9561, time: 287.9954135417938\n",
      "epoch: 181, train_loss: 0.2419, test_metric: 0.9562, time: 287.8429503440857\n",
      "epoch: 182, train_loss: 0.2488, test_metric: 0.9568, time: 287.7730700969696\n",
      "epoch: 184, train_loss: 0.2411, test_metric: 0.9577, time: 287.58940267562866\n",
      "epoch: 185, train_loss: 0.2388, test_metric: 0.9572, time: 287.6384561061859\n",
      "epoch: 186, train_loss: 0.2435, test_metric: 0.9577, time: 287.7482395172119\n",
      "epoch: 187, train_loss: 0.236, test_metric: 0.959, time: 287.74405550956726\n",
      "epoch: 188, train_loss: 0.234, test_metric: 0.9582, time: 287.7025640010834\n",
      "epoch: 189, train_loss: 0.2336, test_metric: 0.9573, time: 287.7414495944977\n",
      "epoch: 190, train_loss: 0.2328, test_metric: 0.9571, time: 287.7058012485504\n",
      "epoch: 191, train_loss: 0.2303, test_metric: 0.9568, time: 287.65177369117737\n",
      "epoch: 192, train_loss: 0.2289, test_metric: 0.9579, time: 287.7463176250458\n",
      "epoch: 193, train_loss: 0.2337, test_metric: 0.9544, time: 287.690701007843\n",
      "epoch: 194, train_loss: 0.2274, test_metric: 0.9562, time: 287.6189124584198\n",
      "epoch: 195, train_loss: 0.2223, test_metric: 0.9569, time: 287.66260957717896\n",
      "epoch: 196, train_loss: 0.2279, test_metric: 0.9588, time: 287.66030645370483\n",
      "epoch: 197, train_loss: 0.224, test_metric: 0.9567, time: 287.83279252052307\n",
      "epoch: 198, train_loss: 0.2245, test_metric: 0.9586, time: 287.8364996910095\n",
      "epoch: 199, train_loss: 0.2226, test_metric: 0.9582, time: 287.7810785770416\n",
      "epoch: 200, train_loss: 0.2222, test_metric: 0.9598, time: 287.75364446640015\n",
      "epoch: 201, train_loss: 0.2172, test_metric: 0.9583, time: 287.7690260410309\n",
      "epoch: 202, train_loss: 0.2206, test_metric: 0.9576, time: 287.74119782447815\n",
      "epoch: 203, train_loss: 0.2189, test_metric: 0.9572, time: 287.7410361766815\n",
      "epoch: 204, train_loss: 0.2149, test_metric: 0.9589, time: 287.73720049858093\n",
      "epoch: 205, train_loss: 0.2229, test_metric: 0.9592, time: 287.7387692928314\n",
      "epoch: 206, train_loss: 0.2187, test_metric: 0.9599, time: 287.67684292793274\n",
      "epoch: 207, train_loss: 0.2159, test_metric: 0.959, time: 287.68626737594604\n",
      "epoch: 208, train_loss: 0.2145, test_metric: 0.9602, time: 287.70076632499695\n",
      "epoch: 209, train_loss: 0.2111, test_metric: 0.9594, time: 287.56732511520386\n",
      "epoch: 210, train_loss: 0.2079, test_metric: 0.9599, time: 287.6665186882019\n",
      "epoch: 211, train_loss: 0.214, test_metric: 0.9588, time: 287.682101726532\n",
      "epoch: 212, train_loss: 0.2123, test_metric: 0.96, time: 287.64566445350647\n",
      "epoch: 213, train_loss: 0.2101, test_metric: 0.9604, time: 287.68754601478577\n",
      "epoch: 214, train_loss: 0.2019, test_metric: 0.9598, time: 287.70719623565674\n",
      "epoch: 215, train_loss: 0.2102, test_metric: 0.9589, time: 287.624347448349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 216, train_loss: 0.2067, test_metric: 0.9588, time: 287.6445314884186\n",
      "epoch: 217, train_loss: 0.2021, test_metric: 0.9591, time: 287.7555732727051\n",
      "epoch: 218, train_loss: 0.2063, test_metric: 0.961, time: 287.795289516449\n",
      "epoch: 219, train_loss: 0.2037, test_metric: 0.9595, time: 287.84113788604736\n",
      "epoch: 220, train_loss: 0.2048, test_metric: 0.9587, time: 287.84378814697266\n",
      "epoch: 221, train_loss: 0.2069, test_metric: 0.9578, time: 287.67720079421997\n",
      "epoch: 222, train_loss: 0.204, test_metric: 0.9584, time: 287.70468521118164\n",
      "epoch: 223, train_loss: 0.2024, test_metric: 0.9594, time: 287.7460083961487\n",
      "epoch: 224, train_loss: 0.2044, test_metric: 0.959, time: 287.6248080730438\n",
      "epoch: 225, train_loss: 0.2018, test_metric: 0.9596, time: 287.7586979866028\n",
      "epoch: 226, train_loss: 0.1963, test_metric: 0.9602, time: 287.6660256385803\n",
      "epoch: 227, train_loss: 0.2032, test_metric: 0.9592, time: 287.7652473449707\n",
      "epoch: 228, train_loss: 0.197, test_metric: 0.9597, time: 287.7005877494812\n",
      "epoch: 229, train_loss: 0.2006, test_metric: 0.9603, time: 287.6734845638275\n",
      "epoch: 230, train_loss: 0.1997, test_metric: 0.9602, time: 287.6224820613861\n",
      "epoch: 231, train_loss: 0.1986, test_metric: 0.9592, time: 287.65865993499756\n",
      "epoch: 232, train_loss: 0.1952, test_metric: 0.9596, time: 287.60980200767517\n",
      "epoch: 233, train_loss: 0.195, test_metric: 0.9615, time: 287.60594868659973\n",
      "epoch: 234, train_loss: 0.1967, test_metric: 0.9601, time: 287.70331144332886\n",
      "epoch: 235, train_loss: 0.2, test_metric: 0.9611, time: 287.5972695350647\n",
      "epoch: 236, train_loss: 0.2014, test_metric: 0.9608, time: 287.6825819015503\n",
      "epoch: 237, train_loss: 0.1992, test_metric: 0.9609, time: 287.7334854602814\n",
      "epoch: 238, train_loss: 0.1937, test_metric: 0.96, time: 287.61950182914734\n",
      "epoch: 239, train_loss: 0.1943, test_metric: 0.9596, time: 287.6544260978699\n",
      "epoch: 240, train_loss: 0.1983, test_metric: 0.9607, time: 287.57260513305664\n",
      "epoch: 241, train_loss: 0.1943, test_metric: 0.9604, time: 287.61152935028076\n",
      "epoch: 242, train_loss: 0.1954, test_metric: 0.9592, time: 287.95617485046387\n",
      "epoch: 243, train_loss: 0.1922, test_metric: 0.9607, time: 287.63423228263855\n",
      "epoch: 244, train_loss: 0.1974, test_metric: 0.9602, time: 287.73708176612854\n",
      "epoch: 245, train_loss: 0.2, test_metric: 0.9606, time: 287.64549231529236\n",
      "epoch: 246, train_loss: 0.1975, test_metric: 0.9597, time: 287.62026357650757\n",
      "epoch: 247, train_loss: 0.198, test_metric: 0.96, time: 287.63662219047546\n",
      "epoch: 248, train_loss: 0.1958, test_metric: 0.9603, time: 287.49577140808105\n",
      "epoch: 249, train_loss: 0.2041, test_metric: 0.9609, time: 287.51443314552307\n",
      "clean    0.9609\n",
      "fgsm     0.4654\n",
      "pgd      0.1473\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<driver.driver.ABC_Driver at 0x7f0b5ca118b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = cifar10_args\n",
    "data = None\n",
    "# data = atd2022.io.read_csv()\n",
    "# data = pd.read_csv('/scratch/mfeng/data/ABC/Wiki_Traffic/filled_selected_train_1.csv', index_col=0, header=[0,1,2,3], parse_dates=True)\n",
    "# data = pd.read_csv('/scratch/mfeng/data/ABC/LA_Traffic/LA_Traffic.csv', index_col=0)\n",
    "# data = data.head(200)\n",
    "\n",
    "driver = ABC_Driver(args, data, record_path=None, if_hash=False)\n",
    "driver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use: ['cuda:4', 'cuda:5']\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "add record: 03/16/2023 14:44\n",
      "epoch: 0, train_loss: 1.9898, test_metric: 0.4628, time: 428.3412141799927\n",
      "epoch: 1, train_loss: 1.3732, test_metric: 0.601, time: 430.7435441017151\n",
      "epoch: 2, train_loss: 1.1166, test_metric: 0.6819, time: 430.48061871528625\n",
      "epoch: 3, train_loss: 0.94, test_metric: 0.7446, time: 430.6922826766968\n",
      "epoch: 4, train_loss: 0.8139, test_metric: 0.7514, time: 429.90587282180786\n",
      "epoch: 5, train_loss: 0.7247, test_metric: 0.7844, time: 430.03293800354004\n",
      "epoch: 6, train_loss: 0.6711, test_metric: 0.8005, time: 430.80587100982666\n",
      "epoch: 7, train_loss: 0.6125, test_metric: 0.8136, time: 430.6304352283478\n",
      "epoch: 8, train_loss: 0.5728, test_metric: 0.8156, time: 430.8235137462616\n",
      "epoch: 9, train_loss: 0.5458, test_metric: 0.8321, time: 430.38902282714844\n",
      "epoch: 10, train_loss: 0.5175, test_metric: 0.8316, time: 430.48436546325684\n",
      "epoch: 11, train_loss: 0.4909, test_metric: 0.8394, time: 430.71942377090454\n",
      "epoch: 12, train_loss: 0.4712, test_metric: 0.8562, time: 430.4596788883209\n",
      "epoch: 13, train_loss: 0.4567, test_metric: 0.8516, time: 430.1802043914795\n",
      "epoch: 14, train_loss: 0.4444, test_metric: 0.8434, time: 435.0415849685669\n",
      "epoch: 15, train_loss: 0.427, test_metric: 0.8588, time: 442.61074900627136\n",
      "epoch: 16, train_loss: 0.4163, test_metric: 0.862, time: 442.8447046279907\n",
      "epoch: 17, train_loss: 0.4074, test_metric: 0.8651, time: 442.9194643497467\n",
      "epoch: 18, train_loss: 0.3978, test_metric: 0.8499, time: 442.97318744659424\n",
      "epoch: 19, train_loss: 0.3834, test_metric: 0.8733, time: 442.81230759620667\n",
      "epoch: 20, train_loss: 0.3744, test_metric: 0.8693, time: 442.95311975479126\n",
      "epoch: 21, train_loss: 0.3706, test_metric: 0.8674, time: 442.72943687438965\n",
      "epoch: 22, train_loss: 0.365, test_metric: 0.8623, time: 443.04350185394287\n",
      "epoch: 23, train_loss: 0.3578, test_metric: 0.8598, time: 443.24417448043823\n",
      "epoch: 24, train_loss: 0.3522, test_metric: 0.8837, time: 442.8008406162262\n",
      "epoch: 25, train_loss: 0.3465, test_metric: 0.8736, time: 442.9054870605469\n",
      "epoch: 26, train_loss: 0.3502, test_metric: 0.8873, time: 443.1994595527649\n",
      "epoch: 27, train_loss: 0.3406, test_metric: 0.878, time: 442.88069128990173\n",
      "epoch: 28, train_loss: 0.3389, test_metric: 0.8797, time: 442.9144914150238\n",
      "epoch: 29, train_loss: 0.3364, test_metric: 0.875, time: 442.83239698410034\n",
      "epoch: 30, train_loss: 0.214, test_metric: 0.9071, time: 443.01119017601013\n",
      "epoch: 31, train_loss: 0.1976, test_metric: 0.9088, time: 442.8087899684906\n",
      "epoch: 32, train_loss: 0.1921, test_metric: 0.9009, time: 442.9392960071564\n",
      "epoch: 33, train_loss: 0.1921, test_metric: 0.8959, time: 442.87438440322876\n",
      "epoch: 34, train_loss: 0.1866, test_metric: 0.9047, time: 442.5601873397827\n",
      "epoch: 35, train_loss: 0.1984, test_metric: 0.902, time: 442.86409878730774\n",
      "epoch: 36, train_loss: 0.1887, test_metric: 0.904, time: 442.9028582572937\n",
      "epoch: 37, train_loss: 0.1897, test_metric: 0.9, time: 443.046897649765\n",
      "epoch: 38, train_loss: 0.1945, test_metric: 0.8957, time: 442.8900783061981\n",
      "epoch: 39, train_loss: 0.1912, test_metric: 0.8879, time: 443.0398864746094\n",
      "epoch: 40, train_loss: 0.1924, test_metric: 0.9027, time: 443.12923312187195\n",
      "epoch: 41, train_loss: 0.1866, test_metric: 0.9037, time: 442.9710876941681\n",
      "epoch: 42, train_loss: 0.1901, test_metric: 0.8982, time: 442.86653232574463\n",
      "epoch: 43, train_loss: 0.1859, test_metric: 0.8969, time: 442.7591507434845\n",
      "epoch: 44, train_loss: 0.1893, test_metric: 0.8969, time: 443.21903228759766\n",
      "epoch: 45, train_loss: 0.1859, test_metric: 0.8984, time: 442.96886944770813\n",
      "epoch: 46, train_loss: 0.1857, test_metric: 0.9027, time: 442.75049090385437\n",
      "epoch: 47, train_loss: 0.1848, test_metric: 0.9032, time: 443.2589259147644\n",
      "epoch: 48, train_loss: 0.1828, test_metric: 0.9047, time: 442.9258670806885\n",
      "epoch: 49, train_loss: 0.1815, test_metric: 0.9055, time: 442.880886554718\n",
      "epoch: 50, train_loss: 0.1816, test_metric: 0.9062, time: 442.91236996650696\n",
      "epoch: 51, train_loss: 0.1805, test_metric: 0.8983, time: 443.16621446609497\n",
      "epoch: 52, train_loss: 0.1807, test_metric: 0.9017, time: 441.61025643348694\n",
      "epoch: 53, train_loss: 0.1727, test_metric: 0.9007, time: 436.66281914711\n",
      "epoch: 54, train_loss: 0.1752, test_metric: 0.8938, time: 443.08490204811096\n",
      "epoch: 55, train_loss: 0.1761, test_metric: 0.8961, time: 442.9819974899292\n",
      "epoch: 56, train_loss: 0.1739, test_metric: 0.8907, time: 442.22888135910034\n",
      "epoch: 57, train_loss: 0.1742, test_metric: 0.8954, time: 441.86303758621216\n",
      "epoch: 58, train_loss: 0.1688, test_metric: 0.9023, time: 442.9414713382721\n",
      "epoch: 59, train_loss: 0.1657, test_metric: 0.9036, time: 443.0081059932709\n",
      "epoch: 60, train_loss: 0.0914, test_metric: 0.9216, time: 443.22536849975586\n",
      "epoch: 61, train_loss: 0.0713, test_metric: 0.9213, time: 443.33809661865234\n",
      "epoch: 62, train_loss: 0.0649, test_metric: 0.9189, time: 443.08184266090393\n",
      "epoch: 63, train_loss: 0.0616, test_metric: 0.9221, time: 443.0284569263458\n",
      "epoch: 64, train_loss: 0.067, test_metric: 0.9221, time: 443.1804733276367\n",
      "epoch: 65, train_loss: 0.0708, test_metric: 0.9187, time: 443.35185074806213\n",
      "epoch: 66, train_loss: 0.0714, test_metric: 0.9187, time: 444.94862484931946\n",
      "epoch: 67, train_loss: 0.0677, test_metric: 0.9206, time: 446.26506447792053\n",
      "epoch: 68, train_loss: 0.0725, test_metric: 0.9129, time: 446.4072105884552\n",
      "epoch: 69, train_loss: 0.0733, test_metric: 0.9161, time: 445.07793045043945\n",
      "epoch: 70, train_loss: 0.0742, test_metric: 0.9167, time: 425.41788387298584\n",
      "epoch: 71, train_loss: 0.0777, test_metric: 0.9154, time: 414.76452231407166\n",
      "epoch: 72, train_loss: 0.0767, test_metric: 0.9116, time: 414.90273094177246\n",
      "epoch: 73, train_loss: 0.0769, test_metric: 0.9156, time: 414.9595708847046\n",
      "epoch: 74, train_loss: 0.0787, test_metric: 0.9156, time: 414.923317193985\n",
      "epoch: 75, train_loss: 0.0791, test_metric: 0.9139, time: 415.1261146068573\n",
      "epoch: 76, train_loss: 0.0833, test_metric: 0.9139, time: 415.00452947616577\n",
      "epoch: 77, train_loss: 0.0737, test_metric: 0.9121, time: 415.11877369880676\n",
      "epoch: 78, train_loss: 0.0816, test_metric: 0.9163, time: 415.00768423080444\n",
      "epoch: 79, train_loss: 0.0779, test_metric: 0.9084, time: 414.9794409275055\n",
      "epoch: 80, train_loss: 0.0838, test_metric: 0.9131, time: 415.14621925354004\n",
      "epoch: 81, train_loss: 0.0845, test_metric: 0.9143, time: 415.0013175010681\n",
      "epoch: 82, train_loss: 0.0856, test_metric: 0.9139, time: 419.9801754951477\n",
      "epoch: 83, train_loss: 0.0818, test_metric: 0.9118, time: 443.3750970363617\n",
      "epoch: 84, train_loss: 0.0791, test_metric: 0.9135, time: 443.42299795150757\n",
      "epoch: 85, train_loss: 0.0892, test_metric: 0.9111, time: 444.3532078266144\n",
      "epoch: 86, train_loss: 0.0811, test_metric: 0.9159, time: 443.66399812698364\n",
      "epoch: 87, train_loss: 0.0824, test_metric: 0.9095, time: 443.7019555568695\n",
      "epoch: 88, train_loss: 0.0864, test_metric: 0.9091, time: 443.8279564380646\n",
      "epoch: 89, train_loss: 0.0886, test_metric: 0.9179, time: 443.98969984054565\n",
      "epoch: 90, train_loss: 0.0396, test_metric: 0.9348, time: 443.921550989151\n",
      "epoch: 91, train_loss: 0.0246, test_metric: 0.9295, time: 443.3901398181915\n",
      "epoch: 92, train_loss: 0.02, test_metric: 0.9301, time: 441.37327432632446\n",
      "epoch: 93, train_loss: 0.0186, test_metric: 0.933, time: 443.41509342193604\n",
      "epoch: 94, train_loss: 0.017, test_metric: 0.9305, time: 443.14462757110596\n",
      "epoch: 95, train_loss: 0.0185, test_metric: 0.9282, time: 443.639023065567\n",
      "epoch: 96, train_loss: 0.0143, test_metric: 0.9307, time: 441.9194223880768\n",
      "epoch: 97, train_loss: 0.0143, test_metric: 0.9299, time: 442.4729526042938\n",
      "epoch: 98, train_loss: 0.015, test_metric: 0.929, time: 443.3958971500397\n",
      "epoch: 99, train_loss: 0.0171, test_metric: 0.9291, time: 443.4482328891754\n",
      "epoch: 100, train_loss: 0.018, test_metric: 0.9268, time: 443.2124011516571\n",
      "epoch: 101, train_loss: 0.0174, test_metric: 0.9279, time: 442.6756360530853\n",
      "epoch: 102, train_loss: 0.0159, test_metric: 0.9308, time: 443.30225944519043\n",
      "epoch: 103, train_loss: 0.0197, test_metric: 0.9322, time: 443.2928409576416\n",
      "epoch: 104, train_loss: 0.0262, test_metric: 0.9284, time: 443.67275047302246\n",
      "epoch: 105, train_loss: 0.0213, test_metric: 0.9286, time: 443.42022681236267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 106, train_loss: 0.0205, test_metric: 0.923, time: 443.2584888935089\n",
      "epoch: 107, train_loss: 0.0238, test_metric: 0.9302, time: 442.88967728614807\n",
      "epoch: 108, train_loss: 0.0259, test_metric: 0.9195, time: 443.39852261543274\n",
      "epoch: 109, train_loss: 0.0282, test_metric: 0.9257, time: 443.5046067237854\n",
      "epoch: 110, train_loss: 0.0272, test_metric: 0.9271, time: 442.1726689338684\n",
      "epoch: 111, train_loss: 0.0238, test_metric: 0.9259, time: 443.5874092578888\n",
      "epoch: 112, train_loss: 0.0267, test_metric: 0.927, time: 442.9516682624817\n",
      "epoch: 113, train_loss: 0.0306, test_metric: 0.9215, time: 442.9449760913849\n",
      "epoch: 114, train_loss: 0.0365, test_metric: 0.924, time: 443.6515793800354\n",
      "epoch: 115, train_loss: 0.0314, test_metric: 0.9169, time: 441.73201513290405\n",
      "epoch: 116, train_loss: 0.0376, test_metric: 0.9248, time: 442.7366020679474\n",
      "epoch: 117, train_loss: 0.0357, test_metric: 0.9233, time: 443.548152923584\n",
      "epoch: 118, train_loss: 0.0311, test_metric: 0.9208, time: 442.9917645454407\n",
      "epoch: 119, train_loss: 0.0294, test_metric: 0.9228, time: 443.1664791107178\n",
      "epoch: 120, train_loss: 0.0147, test_metric: 0.9323, time: 443.41545701026917\n",
      "epoch: 121, train_loss: 0.0095, test_metric: 0.9338, time: 442.6105227470398\n",
      "epoch: 122, train_loss: 0.0079, test_metric: 0.9371, time: 443.4841113090515\n",
      "epoch: 123, train_loss: 0.0064, test_metric: 0.9337, time: 443.45004773139954\n",
      "epoch: 124, train_loss: 0.0062, test_metric: 0.9374, time: 443.40024852752686\n",
      "epoch: 125, train_loss: 0.0056, test_metric: 0.9379, time: 442.48136019706726\n",
      "epoch: 126, train_loss: 0.0053, test_metric: 0.9362, time: 443.1851119995117\n",
      "epoch: 127, train_loss: 0.0044, test_metric: 0.9341, time: 442.83949184417725\n",
      "epoch: 128, train_loss: 0.0045, test_metric: 0.9366, time: 443.0971176624298\n",
      "epoch: 129, train_loss: 0.0041, test_metric: 0.9353, time: 442.6845700740814\n",
      "epoch: 130, train_loss: 0.0043, test_metric: 0.9364, time: 443.4563407897949\n",
      "epoch: 131, train_loss: 0.0038, test_metric: 0.9358, time: 442.69997358322144\n",
      "epoch: 132, train_loss: 0.0038, test_metric: 0.9374, time: 443.3349983692169\n",
      "epoch: 133, train_loss: 0.0045, test_metric: 0.937, time: 442.71553897857666\n",
      "epoch: 134, train_loss: 0.0043, test_metric: 0.9353, time: 443.421498298645\n",
      "epoch: 135, train_loss: 0.0034, test_metric: 0.9369, time: 443.0493187904358\n",
      "epoch: 136, train_loss: 0.0031, test_metric: 0.9354, time: 443.0971329212189\n",
      "epoch: 137, train_loss: 0.0029, test_metric: 0.9365, time: 443.5015239715576\n",
      "epoch: 138, train_loss: 0.0029, test_metric: 0.9354, time: 443.29276847839355\n",
      "epoch: 139, train_loss: 0.003, test_metric: 0.9334, time: 443.612375497818\n",
      "epoch: 140, train_loss: 0.0027, test_metric: 0.9337, time: 443.518718957901\n",
      "epoch: 141, train_loss: 0.0026, test_metric: 0.9363, time: 443.3588502407074\n",
      "epoch: 142, train_loss: 0.0033, test_metric: 0.9357, time: 443.2370128631592\n",
      "epoch: 143, train_loss: 0.0029, test_metric: 0.9377, time: 442.68643140792847\n",
      "epoch: 144, train_loss: 0.0031, test_metric: 0.9361, time: 443.36551547050476\n",
      "epoch: 145, train_loss: 0.0029, test_metric: 0.9358, time: 443.00846695899963\n",
      "epoch: 146, train_loss: 0.0029, test_metric: 0.9362, time: 441.992769241333\n",
      "epoch: 147, train_loss: 0.0022, test_metric: 0.9377, time: 442.50344944000244\n",
      "epoch: 148, train_loss: 0.002, test_metric: 0.9389, time: 443.47289085388184\n",
      "epoch: 149, train_loss: 0.0028, test_metric: 0.9366, time: 441.72384691238403\n",
      "epoch: 150, train_loss: 0.0022, test_metric: 0.9386, time: 443.3843994140625\n",
      "epoch: 151, train_loss: 0.0019, test_metric: 0.939, time: 441.51902437210083\n",
      "epoch: 152, train_loss: 0.0019, test_metric: 0.9376, time: 442.8420875072479\n",
      "epoch: 153, train_loss: 0.0016, test_metric: 0.9397, time: 443.6828410625458\n",
      "epoch: 154, train_loss: 0.0018, test_metric: 0.9394, time: 443.2131464481354\n",
      "epoch: 155, train_loss: 0.0016, test_metric: 0.9407, time: 443.4080045223236\n",
      "epoch: 156, train_loss: 0.0011, test_metric: 0.9397, time: 443.0778479576111\n",
      "epoch: 157, train_loss: 0.0011, test_metric: 0.9403, time: 443.34687519073486\n",
      "epoch: 158, train_loss: 0.0013, test_metric: 0.9398, time: 443.4342119693756\n",
      "epoch: 159, train_loss: 0.0013, test_metric: 0.9391, time: 443.5725111961365\n",
      "epoch: 160, train_loss: 0.0012, test_metric: 0.9395, time: 443.3960270881653\n",
      "epoch: 161, train_loss: 0.0013, test_metric: 0.9398, time: 443.3398611545563\n",
      "epoch: 162, train_loss: 0.0011, test_metric: 0.9402, time: 443.0708668231964\n",
      "epoch: 163, train_loss: 0.0011, test_metric: 0.9387, time: 443.3881685733795\n",
      "epoch: 164, train_loss: 0.0012, test_metric: 0.9402, time: 442.93694496154785\n",
      "epoch: 165, train_loss: 0.0012, test_metric: 0.9414, time: 443.2033784389496\n",
      "epoch: 166, train_loss: 0.0013, test_metric: 0.9413, time: 443.1336290836334\n",
      "epoch: 167, train_loss: 0.0013, test_metric: 0.9407, time: 443.31385350227356\n",
      "epoch: 168, train_loss: 0.0011, test_metric: 0.9407, time: 441.53650188446045\n",
      "epoch: 169, train_loss: 0.0011, test_metric: 0.9412, time: 442.98341155052185\n",
      "epoch: 170, train_loss: 0.0012, test_metric: 0.9425, time: 442.76584458351135\n",
      "epoch: 171, train_loss: 0.0011, test_metric: 0.9429, time: 443.42412662506104\n",
      "epoch: 172, train_loss: 0.0012, test_metric: 0.9413, time: 443.4683451652527\n",
      "epoch: 173, train_loss: 0.001, test_metric: 0.9419, time: 443.5329649448395\n",
      "epoch: 174, train_loss: 0.0011, test_metric: 0.9417, time: 441.7731330394745\n",
      "epoch: 175, train_loss: 0.0012, test_metric: 0.9415, time: 443.0361981391907\n",
      "epoch: 176, train_loss: 0.0013, test_metric: 0.9421, time: 444.0689465999603\n",
      "epoch: 177, train_loss: 0.0011, test_metric: 0.9414, time: 443.93227195739746\n",
      "epoch: 178, train_loss: 0.0012, test_metric: 0.9425, time: 443.85747027397156\n",
      "epoch: 179, train_loss: 0.0012, test_metric: 0.9405, time: 444.0186460018158\n",
      "epoch: 180, train_loss: 0.001, test_metric: 0.9423, time: 444.18983006477356\n",
      "epoch: 181, train_loss: 0.0011, test_metric: 0.9433, time: 444.09747290611267\n",
      "epoch: 182, train_loss: 0.001, test_metric: 0.9416, time: 444.162162065506\n",
      "epoch: 183, train_loss: 0.001, test_metric: 0.942, time: 444.01815581321716\n",
      "epoch: 184, train_loss: 0.001, test_metric: 0.9419, time: 443.78137707710266\n",
      "epoch: 185, train_loss: 0.0014, test_metric: 0.942, time: 444.06980419158936\n",
      "epoch: 186, train_loss: 0.0009, test_metric: 0.9415, time: 443.8429789543152\n",
      "epoch: 187, train_loss: 0.0009, test_metric: 0.9411, time: 443.7577681541443\n",
      "epoch: 188, train_loss: 0.0012, test_metric: 0.9424, time: 443.1852033138275\n",
      "epoch: 189, train_loss: 0.0009, test_metric: 0.9428, time: 442.9591541290283\n",
      "epoch: 190, train_loss: 0.0009, test_metric: 0.9419, time: 443.76951694488525\n",
      "epoch: 191, train_loss: 0.0008, test_metric: 0.9437, time: 444.11666989326477\n",
      "epoch: 192, train_loss: 0.0009, test_metric: 0.9435, time: 444.1939001083374\n",
      "epoch: 193, train_loss: 0.0009, test_metric: 0.9433, time: 444.2467441558838\n",
      "epoch: 194, train_loss: 0.0009, test_metric: 0.9426, time: 444.1086890697479\n",
      "epoch: 195, train_loss: 0.0009, test_metric: 0.9426, time: 444.16980624198914\n",
      "epoch: 196, train_loss: 0.001, test_metric: 0.943, time: 444.1940622329712\n",
      "epoch: 197, train_loss: 0.0009, test_metric: 0.9418, time: 443.9805963039398\n",
      "epoch: 198, train_loss: 0.0009, test_metric: 0.943, time: 444.10602355003357\n",
      "epoch: 199, train_loss: 0.0009, test_metric: 0.9411, time: 444.21919679641724\n",
      "epoch: 200, train_loss: 0.0009, test_metric: 0.9426, time: 443.8597605228424\n",
      "epoch: 201, train_loss: 0.0008, test_metric: 0.9412, time: 444.11601996421814\n",
      "epoch: 202, train_loss: 0.0009, test_metric: 0.942, time: 444.113862991333\n",
      "epoch: 203, train_loss: 0.0011, test_metric: 0.9412, time: 444.368629693985\n",
      "epoch: 204, train_loss: 0.0009, test_metric: 0.9417, time: 443.75739550590515\n",
      "epoch: 205, train_loss: 0.001, test_metric: 0.9406, time: 444.0733618736267\n",
      "epoch: 206, train_loss: 0.0012, test_metric: 0.9415, time: 444.0418918132782\n",
      "epoch: 207, train_loss: 0.0008, test_metric: 0.9418, time: 443.90214443206787\n",
      "epoch: 208, train_loss: 0.0009, test_metric: 0.9422, time: 444.16587710380554\n",
      "epoch: 209, train_loss: 0.0009, test_metric: 0.9428, time: 444.2138113975525\n",
      "epoch: 210, train_loss: 0.001, test_metric: 0.9406, time: 444.1322808265686\n",
      "epoch: 211, train_loss: 0.0009, test_metric: 0.9425, time: 443.9763960838318\n",
      "epoch: 212, train_loss: 0.001, test_metric: 0.9426, time: 443.8612289428711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 213, train_loss: 0.0008, test_metric: 0.9417, time: 443.6895661354065\n",
      "epoch: 214, train_loss: 0.001, test_metric: 0.9414, time: 443.99684381484985\n",
      "epoch: 215, train_loss: 0.0011, test_metric: 0.9428, time: 443.7667384147644\n",
      "epoch: 216, train_loss: 0.0009, test_metric: 0.9412, time: 443.91667675971985\n",
      "epoch: 217, train_loss: 0.0009, test_metric: 0.9411, time: 443.3837683200836\n",
      "epoch: 218, train_loss: 0.0008, test_metric: 0.9428, time: 443.8919117450714\n",
      "epoch: 219, train_loss: 0.0009, test_metric: 0.9414, time: 443.93101692199707\n",
      "epoch: 220, train_loss: 0.0009, test_metric: 0.9411, time: 443.9579005241394\n",
      "epoch: 221, train_loss: 0.0008, test_metric: 0.9421, time: 443.96986961364746\n",
      "epoch: 222, train_loss: 0.0008, test_metric: 0.9422, time: 443.9425678253174\n",
      "epoch: 223, train_loss: 0.0008, test_metric: 0.943, time: 443.950558423996\n",
      "epoch: 224, train_loss: 0.0009, test_metric: 0.9409, time: 443.7249915599823\n",
      "epoch: 225, train_loss: 0.0009, test_metric: 0.9425, time: 443.76967906951904\n",
      "epoch: 226, train_loss: 0.0008, test_metric: 0.9395, time: 443.8903205394745\n",
      "epoch: 227, train_loss: 0.001, test_metric: 0.9408, time: 443.98021817207336\n",
      "epoch: 228, train_loss: 0.0009, test_metric: 0.9421, time: 444.04104948043823\n",
      "epoch: 229, train_loss: 0.0009, test_metric: 0.942, time: 444.22211599349976\n",
      "epoch: 230, train_loss: 0.0009, test_metric: 0.9415, time: 444.10056591033936\n",
      "epoch: 231, train_loss: 0.0008, test_metric: 0.9422, time: 443.7770013809204\n",
      "epoch: 232, train_loss: 0.0009, test_metric: 0.9423, time: 443.82707691192627\n",
      "epoch: 233, train_loss: 0.0008, test_metric: 0.9414, time: 444.1843726634979\n",
      "epoch: 234, train_loss: 0.0008, test_metric: 0.9423, time: 444.06738471984863\n",
      "epoch: 235, train_loss: 0.0008, test_metric: 0.9407, time: 444.0900704860687\n",
      "epoch: 236, train_loss: 0.0008, test_metric: 0.9407, time: 444.17315578460693\n",
      "epoch: 237, train_loss: 0.0009, test_metric: 0.942, time: 443.9240417480469\n",
      "epoch: 238, train_loss: 0.0008, test_metric: 0.9428, time: 444.069128036499\n",
      "epoch: 239, train_loss: 0.0009, test_metric: 0.9423, time: 444.0048985481262\n",
      "epoch: 240, train_loss: 0.0008, test_metric: 0.9434, time: 444.0855140686035\n",
      "epoch: 241, train_loss: 0.0008, test_metric: 0.9414, time: 443.8715260028839\n",
      "epoch: 242, train_loss: 0.0008, test_metric: 0.9413, time: 443.99454498291016\n",
      "epoch: 243, train_loss: 0.0007, test_metric: 0.9425, time: 443.9057848453522\n",
      "epoch: 244, train_loss: 0.0009, test_metric: 0.9422, time: 444.0633933544159\n",
      "epoch: 245, train_loss: 0.0009, test_metric: 0.9414, time: 443.9568016529083\n",
      "epoch: 246, train_loss: 0.0008, test_metric: 0.9428, time: 444.0794003009796\n",
      "epoch: 247, train_loss: 0.001, test_metric: 0.9408, time: 445.34355092048645\n",
      "epoch: 248, train_loss: 0.0008, test_metric: 0.9428, time: 446.25957441329956\n",
      "epoch: 249, train_loss: 0.0008, test_metric: 0.9422, time: 446.2372679710388\n",
      "clean    0.9422\n",
      "fgsm     0.5360\n",
      "pgd      0.3277\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<driver.driver.ABC_Driver at 0x7f4e683dbdf0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = cifar10_args\n",
    "data = None\n",
    "# data = atd2022.io.read_csv()\n",
    "# data = pd.read_csv('/scratch/mfeng/data/ABC/Wiki_Traffic/filled_selected_train_1.csv', index_col=0, header=[0,1,2,3], parse_dates=True)\n",
    "# data = pd.read_csv('/scratch/mfeng/data/ABC/LA_Traffic/LA_Traffic.csv', index_col=0)\n",
    "# data = data.head(200)\n",
    "\n",
    "driver = ABC_Driver(args, data, record_path=None, if_hash=False)\n",
    "driver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(driver.model.state_dict(), \"save/CIFAR10_CNM_2023_03_22.pt\")\n",
    "# driver.model.load_state_dict(torch.load(\"save/CIFAR10_CNN_2023_03_07.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in driver.model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1649269"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "0: 61\n",
      "1: 62\n",
      "2: 53\n",
      "3: 67\n",
      "4: 63\n",
      "5: 62\n",
      "6: 56\n",
      "7: 67\n",
      "8: 65\n",
      "9: 61\n",
      "10: 63\n",
      "11: 60\n",
      "12: 61\n",
      "13: 57\n",
      "14: 63\n",
      "15: 62\n",
      "16: 64\n",
      "17: 60\n",
      "18: 59\n",
      "19: 60\n",
      "20: 61\n",
      "21: 57\n",
      "22: 65\n",
      "23: 62\n",
      "24: 62\n",
      "25: 68\n",
      "26: 56\n",
      "27: 59\n",
      "28: 55\n",
      "29: 62\n",
      "30: 62\n",
      "31: 53\n",
      "32: 54\n",
      "33: 67\n",
      "34: 60\n",
      "35: 55\n",
      "36: 53\n",
      "37: 64\n",
      "38: 55\n",
      "39: 62\n",
      "40: 65\n",
      "41: 62\n",
      "42: 55\n",
      "43: 63\n",
      "44: 63\n",
      "45: 69\n",
      "46: 64\n",
      "47: 57\n",
      "48: 59\n",
      "49: 63\n",
      "50: 57\n",
      "51: 65\n",
      "52: 68\n",
      "53: 53\n",
      "54: 58\n",
      "55: 67\n",
      "56: 71\n",
      "57: 56\n",
      "58: 71\n",
      "59: 60\n",
      "60: 61\n",
      "61: 61\n",
      "62: 59\n",
      "63: 51\n",
      "64: 65\n",
      "65: 66\n",
      "66: 58\n",
      "67: 65\n",
      "68: 71\n",
      "69: 59\n",
      "70: 54\n",
      "71: 63\n",
      "72: 58\n",
      "73: 60\n",
      "74: 60\n",
      "75: 56\n",
      "76: 60\n",
      "77: 52\n",
      "78: 60\n",
      "79: 61\n",
      "80: 60\n",
      "81: 62\n",
      "82: 52\n",
      "83: 66\n",
      "84: 62\n",
      "85: 62\n",
      "86: 63\n",
      "87: 65\n",
      "88: 59\n",
      "89: 62\n",
      "90: 62\n",
      "91: 58\n",
      "92: 62\n",
      "93: 60\n",
      "94: 62\n",
      "95: 55\n",
      "96: 60\n",
      "97: 63\n",
      "98: 57\n",
      "99: 57\n",
      "tensor(0.3927, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import foolbox as fb\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "preprocessing = dict(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010], axis=-3)\n",
    "bounds = (0, 255)\n",
    "driver.model.eval()\n",
    "fmodel = fb.PyTorchModel(driver.model, bounds=bounds,preprocessing=preprocessing, device=torch.device('cuda'))\n",
    "# attack = fb.attacks.LinfPGD(rel_stepsize=0.1, steps=20)\n",
    "attack = fb.attacks.FGSM()\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "testset = datasets.CIFAR10(root='../../data/ABC/CIFAR10', train=False, download=True, transform=transform)\n",
    "predict = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "suc_all = 0\n",
    "for i, (images, labels) in enumerate(predict):\n",
    "    images = images.to(torch.device('cuda'))\n",
    "    labels = labels.to(torch.device('cuda'))\n",
    "    raw, clipped, is_adv = attack(fmodel, images, labels, epsilons=0.005)\n",
    "#     raw, clipped, is_adv = attack(fmodel, images, labels, epsilons=0.031)\n",
    "    suc = is_adv.sum()\n",
    "    suc_all += suc\n",
    "    print(f'{i}: {suc}')\n",
    "attack_accuracy = 1 - suc_all/10000\n",
    "print(attack_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cifar10_args.layers=[\n",
    "#     ('agnostic', ((input_channel, knpp[0], 9), 1, None, None, activation, False)),\n",
    "#     ('agnostic', ((knpp[0], knpp[0], 9), 2, None, None, activation)),\n",
    "#     ('agnostic', ((knpp[0], knpp[1], 9), 2, None, None, activation)),\n",
    "#     ('agnostic', ((knpp[1], knpp[2], 9), 2, None, None, activation)),\n",
    "#     ('agnostic', ((knpp[2], knpp[3], 9), 2, 'first', (2,2), activation)),\n",
    "#     ('agnostic', ((knpp[3], knpp[4], 9), 2, None, None, activation)),\n",
    "#     ('agnostic', ((knpp[4], knpp[5], 9), 2, None, None, activation)),\n",
    "#     ('agnostic', ((knpp[5], knpp[6], 9), 2, 'first', (2,2), activation)),\n",
    "#     ('agnostic', ((knpp[6], knpp[7], 9), 2, None, None, activation)),\n",
    "#     ('agnostic', ((knpp[7], knpp[8], 9), 2, None, None, activation)),\n",
    "#     ('adptavgpool', (1,1)),\n",
    "#     ('linear', (knpp[-1], 10, (1,2,3))),\n",
    "#     ('softmax', (1))\n",
    "# ]\n",
    "\n",
    "# cifar10_args.layers=[\n",
    "#     ('cnn2d', ((input_channel, knpp[0], (3,3), 1, 1), 1, None, None, activation, False)),\n",
    "#     ('cnn2d', ((knpp[0], knpp[0], (3,3), 1, 1), 2, None, None, activation)),\n",
    "#     ('cnn2d', ((knpp[0], knpp[1], (3,3), 1, 1), 2, None, None, activation)),\n",
    "#     ('cnn2d', ((knpp[1], knpp[2], (3,3), 1, 1), 2, None, None, activation)),\n",
    "#     ('cnn2d', ((knpp[2], knpp[3], (3,3), 1, 1), 2, 'first', (2,2), activation)),\n",
    "#     ('cnn2d', ((knpp[3], knpp[4], (3,3), 1, 1), 2, None, None, activation)),\n",
    "#     ('cnn2d', ((knpp[4], knpp[5], (3,3), 1, 1), 2, None, None, activation)),\n",
    "#     ('cnn2d', ((knpp[5], knpp[6], (3,3), 1, 1), 2, 'first', (2,2), activation)),\n",
    "#     ('cnn2d', ((knpp[6], knpp[7], (3,3), 1, 1), 2, None, None, activation)),\n",
    "#     ('cnn2d', ((knpp[7], knpp[8], (3,3), 1, 1), 2, None, None, activation)),\n",
    "#     ('adptavgpool', (1,1)),\n",
    "#     ('linear', (knpp[-1], 10, (1,2,3))),\n",
    "#     ('softmax', (1))\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[('cnn2d', ((3, 16, (3, 3), 1, 1), 1, None, None, 'relu', False)), \n",
    " ('cnn2d', ((16, 16, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((16, 16, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((16, 16, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((16, 32, (3, 3), 1, 1), 2, 'first', (2, 2), 'relu')), \n",
    " ('cnn2d', ((32, 32, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((32, 32, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((32, 64, (3, 3), 1, 1), 2, 'first', (2, 2), 'relu')), \n",
    " ('cnn2d', ((64, 64, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((64, 64, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('adptavgpool', (1, 1)), \n",
    " ('linear', (64, 10, (1, 2, 3))), \n",
    " ('softmax', 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
