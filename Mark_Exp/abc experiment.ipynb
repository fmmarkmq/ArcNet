{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 CNN: 0.98\n",
    "1 CNN: 0.9615 epoch 3\n",
    "1 CNN: 0.9782 epoch 50\n",
    "ABC: 0.9575 batch 100, lr 0.0001, metrics criterion 'CE', epoch 3\n",
    "ABC: 0.9671 batch 100, lr 0.0001, metrics criterion 'CE', epoch 6\n",
    "ABC: 0.9768 epoch 50 kernel_per_pixel 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.tools import dotdict\n",
    "from driver.driver import ABC_Driver\n",
    "from torch_geometric_temporal import METRLADatasetLoader\n",
    "from other_model.other_model import make_default_model\n",
    "import atd2022\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "atd_args = dotdict()\n",
    "\n",
    "atd_args.name = 'atd'\n",
    "atd_args.train_batch_size = 25\n",
    "atd_args.predict_len = 4\n",
    "atd_args.history_len = 7\n",
    "\n",
    "atd_args.train_epochs= 10\n",
    "atd_args.lr = 0.00009\n",
    "atd_args.criterion = 'L1'\n",
    "atd_args.scheduler = None\n",
    "\n",
    "activation = 'relu'\n",
    "pool_name = 'avg'\n",
    "input_channel = 1\n",
    "pixel_number = atd_args.history_len*5200\n",
    "kernel_size = 6\n",
    "knpp = 12\n",
    "knpp2 = atd_args.predict_len\n",
    "\n",
    "atd_args.layers=[\n",
    "    ('agnostic', ((input_channel, knpp, kernel_size), 1, None, None, activation)),\n",
    "    ('agnostic', ((knpp, knpp2, kernel_size), 1, None, None, activation)),\n",
    "    ('linear', (knpp2*atd_args.history_len, atd_args.predict_len, (1,2), 1, (1, atd_args.predict_len))),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_args = dotdict()\n",
    "\n",
    "wt_args.name = 'wiki_traffic'\n",
    "wt_args.train_batch_size = 30\n",
    "wt_args.predict_len = 1\n",
    "wt_args.history_len = 5\n",
    "\n",
    "wt_args.train_epochs= 10\n",
    "wt_args.lr = 0.001\n",
    "wt_args.criterion = 'L1'\n",
    "wt_args.scheduler = None\n",
    "\n",
    "activation = 'relu'\n",
    "pool_name = 'avg'\n",
    "input_channel = 1\n",
    "pixel_number = wt_args.history_len*1400\n",
    "kernel_size = 3\n",
    "knpp = 5\n",
    "knpp2 = 15\n",
    "\n",
    "wt_args.layers=[\n",
    "    ('specific', ((input_channel, knpp, kernel_size), 1, None, None, activation)),\n",
    "    ('specific', ((knpp, knpp2, kernel_size), 1, None, None, activation)),\n",
    "    ('linear', (knpp2*wt_args.history_len, wt_args.predict_len, (1,2), 1, (1, wt_args.predict_len))),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_args = dotdict()\n",
    "\n",
    "lat_args.name = 'lat'\n",
    "lat_args.train_batch_size = 30\n",
    "lat_args.predict_len = 1\n",
    "lat_args.history_len = 5\n",
    "\n",
    "lat_args.train_epochs= 10\n",
    "lat_args.lr = 0.001\n",
    "lat_args.criterion = 'L1'\n",
    "lat_args.scheduler = None\n",
    "\n",
    "activation = 'relu'\n",
    "pool_name = 'avg'\n",
    "input_channel = 1\n",
    "pixel_number = lat_args.history_len*207\n",
    "kernel_size = 3\n",
    "knpp = 5\n",
    "knpp2 = 15\n",
    "\n",
    "lat_args.layers=[\n",
    "    ('specific', ((input_channel, knpp, kernel_size), 1, None, None, activation)),\n",
    "    ('specific', ((knpp, knpp2, kernel_size), 1, None, None, activation)),\n",
    "    ('linear', (knpp2*lat_args.history_len, lat_args.predict_len, (1,2), 1, (1, lat_args.predict_len))),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_args = dotdict()\n",
    "\n",
    "mnist_args.name = 'mnist'\n",
    "mnist_args.train_batch_size = 120\n",
    "mnist_args.predict_batch_size = 100\n",
    "\n",
    "mnist_args.train_epochs = 30\n",
    "mnist_args.lr = 0.001\n",
    "mnist_args.criterion = 'CE'\n",
    "mnist_args.optimizer = 'Adam'\n",
    "mnist_args.scheduler = 'multistep3'\n",
    "\n",
    "activation = 'relu'\n",
    "input_channel = 1\n",
    "knpp = [30,60,120,180,240]\n",
    "\n",
    "mnist_args.layers=[\n",
    "    ('cnn2d', ((input_channel, knpp[0], (7,7), 1, 3, 1, 1), 1, None, None, activation, False)),\n",
    "    ('atc2d', ((knpp[0], knpp[1], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, True)),\n",
    "    ('atc2d', ((knpp[1], knpp[2], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, True)),\n",
    "    ('atc2d', ((knpp[2], knpp[3], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, True)),\n",
    "    ('atc2d', ((knpp[3], knpp[4], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, True)),\n",
    "    ('cnn2d', ((knpp[-1], knpp[-1], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, False)),\n",
    "    ('cnn2d', ((knpp[-1], knpp[-1], (3,3), 1, 0, 1, knpp[0]), 1, None, None, False, False)),\n",
    "    ('adptavgpool', (1,1)),\n",
    "    ('linear', (knpp[-1], 10, (1,2,3))),\n",
    "    ('softmax', (1))\n",
    "]\n",
    "\n",
    "# knpp = [24,48,96,192]\n",
    "# # knpp = [30,60,120,240]\n",
    "\n",
    "# mnist_args.layers=[\n",
    "#     ('cnn2d', ((input_channel, knpp[0], (3,3), 1, 1, 1, 1), 1, None, None, activation, False)),\n",
    "#     ('atc2d', ((knpp[0], knpp[1], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, True)),\n",
    "#     ('atc2d', ((knpp[1], knpp[2], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, True)),\n",
    "#     ('atc2d', ((knpp[2], knpp[3], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, True)),\n",
    "#     ('cnn2d', ((knpp[-1], knpp[-1], (3,3), 1, 0, 1, knpp[0]), 1, None, None, activation, False)),\n",
    "#     ('cnn2d', ((knpp[-1], knpp[-1], (3,3), 1, 0, 1, knpp[0]), 1, None, None, False, False)),\n",
    "#     ('adptavgpool', (1,1)),\n",
    "#     ('linear', (knpp[-1], 10, (1,2,3))),\n",
    "#     ('softmax', (1))\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_args = dotdict()\n",
    "\n",
    "cifar10_args.name = 'cifar10'\n",
    "cifar10_args.train_batch_size = 128\n",
    "cifar10_args.predict_batch_size = 100\n",
    "\n",
    "cifar10_args.train_epochs = 250\n",
    "cifar10_args.lr = 0.001\n",
    "cifar10_args.criterion = 'CE'\n",
    "cifar10_args.optimizer = 'Adam'\n",
    "cifar10_args.scheduler = 'multistep'\n",
    "\n",
    "activation = 'relu'\n",
    "input_channel = 3\n",
    "knpp = [40,80,160,240,320]\n",
    "\n",
    "# cifar10_args.layers=[\n",
    "#     ('cnn2d', ((input_channel, knpp[0], (3,3), 1, 1, 1, 1), 1, None, None, activation, False)),\n",
    "#     ('atc2d', ((knpp[0], knpp[1], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, True)),\n",
    "#     ('atc2d', ((knpp[1], knpp[2], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, True)),\n",
    "#     ('atc2d', ((knpp[2], knpp[3], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, True)),\n",
    "#     ('atc2d', ((knpp[3], knpp[4], (3,3), 1, 1, 1, knpp[0]), 1, 'first', (2,2), activation, True)),\n",
    "#     ('cnn2d', ((knpp[-1], knpp[-1], (3,3), 1, 1, 1, knpp[0]), 1, None, None, activation, False)),\n",
    "#     ('cnn2d', ((knpp[-1], knpp[-1], (3,3), 1, 0, 1, knpp[0]), 1, None, None, False, False)),\n",
    "#     ('adptavgpool', (1,1)),\n",
    "#     ('linear', (knpp[-1], 10, (1,2,3))),\n",
    "#     ('softmax', (1))\n",
    "# ]\n",
    "\n",
    "cifar10_args.layers=[('cnn2d', ((3, 16, (3, 3), 1, 1), 1, None, None, 'relu', False)), \n",
    " ('cnn2d', ((16, 16, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((16, 16, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((16, 16, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((16, 32, (3, 3), 1, 1), 2, 'first', (2, 2), 'relu')), \n",
    " ('cnn2d', ((32, 32, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((32, 32, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((32, 64, (3, 3), 1, 1), 2, 'first', (2, 2), 'relu')), \n",
    " ('cnn2d', ((64, 64, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((64, 64, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('adptavgpool', (1, 1)), \n",
    " ('linear', (64, 10, (1, 2, 3))), \n",
    " ('softmax', 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "add record: 02/20/2023 23:59\n"
     ]
    }
   ],
   "source": [
    "args = cifar10_args\n",
    "data = None\n",
    "# data = atd2022.io.read_csv()\n",
    "# data = pd.read_csv('/scratch/mfeng/data/ABC/Wiki_Traffic/filled_selected_train_1.csv', index_col=0, header=[0,1,2,3], parse_dates=True)\n",
    "# data = pd.read_csv('/scratch/mfeng/data/ABC/LA_Traffic/LA_Traffic.csv', index_col=0)\n",
    "# data = data.head(200)\n",
    "\n",
    "driver = ABC_Driver(args, data, record_path=None, if_hash=False)\n",
    "# driver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 1.6181, test_metric: 0.8198, time: 3627.809912443161\n",
      "epoch: 1, train_loss: 1.6144, test_metric: 0.8241, time: 318.12082505226135\n",
      "epoch: 2, train_loss: 1.6136, test_metric: 0.8213, time: 317.9991126060486\n",
      "epoch: 3, train_loss: 1.6097, test_metric: 0.84, time: 318.2684280872345\n",
      "epoch: 5, train_loss: 1.6043, test_metric: 0.8353, time: 318.33043360710144\n",
      "epoch: 6, train_loss: 1.6029, test_metric: 0.8401, time: 318.1367197036743\n",
      "epoch: 7, train_loss: 1.5976, test_metric: 0.8346, time: 318.0952470302582\n",
      "epoch: 8, train_loss: 1.5967, test_metric: 0.8365, time: 318.26040410995483\n",
      "epoch: 9, train_loss: 1.5933, test_metric: 0.8494, time: 317.99820017814636\n",
      "epoch: 10, train_loss: 1.5913, test_metric: 0.8407, time: 318.1279516220093\n",
      "epoch: 11, train_loss: 1.5877, test_metric: 0.8411, time: 318.28657937049866\n",
      "epoch: 12, train_loss: 1.5894, test_metric: 0.8469, time: 318.07630729675293\n",
      "epoch: 13, train_loss: 1.5864, test_metric: 0.8458, time: 317.9950020313263\n",
      "epoch: 14, train_loss: 1.5824, test_metric: 0.845, time: 318.3077304363251\n",
      "epoch: 15, train_loss: 1.5851, test_metric: 0.8482, time: 317.9402403831482\n",
      "epoch: 16, train_loss: 1.5831, test_metric: 0.8548, time: 317.4949300289154\n",
      "epoch: 17, train_loss: 1.5808, test_metric: 0.8566, time: 317.72171211242676\n",
      "epoch: 18, train_loss: 1.5809, test_metric: 0.8527, time: 318.1367383003235\n",
      "epoch: 19, train_loss: 1.5771, test_metric: 0.8448, time: 317.94119143486023\n",
      "epoch: 20, train_loss: 1.5762, test_metric: 0.85, time: 317.8345055580139\n",
      "epoch: 21, train_loss: 1.5761, test_metric: 0.8456, time: 317.95413970947266\n",
      "epoch: 22, train_loss: 1.5761, test_metric: 0.8523, time: 318.2930588722229\n",
      "epoch: 23, train_loss: 1.5766, test_metric: 0.8355, time: 317.73472714424133\n",
      "epoch: 24, train_loss: 1.5759, test_metric: 0.8624, time: 318.05518221855164\n",
      "epoch: 25, train_loss: 1.5728, test_metric: 0.85, time: 318.08142590522766\n",
      "epoch: 26, train_loss: 1.5716, test_metric: 0.8574, time: 317.43406081199646\n",
      "epoch: 27, train_loss: 1.5719, test_metric: 0.8507, time: 317.69761300086975\n",
      "epoch: 28, train_loss: 1.5678, test_metric: 0.8545, time: 318.10960817337036\n",
      "epoch: 29, train_loss: 1.5708, test_metric: 0.8588, time: 317.85276055336\n",
      "epoch: 30, train_loss: 1.5478, test_metric: 0.8841, time: 317.7481873035431\n",
      "epoch: 31, train_loss: 1.5399, test_metric: 0.8846, time: 317.75258588790894\n",
      "epoch: 32, train_loss: 1.538, test_metric: 0.8831, time: 317.97147393226624\n",
      "epoch: 33, train_loss: 1.5356, test_metric: 0.8835, time: 317.7886075973511\n",
      "epoch: 34, train_loss: 1.5342, test_metric: 0.8851, time: 317.76024985313416\n",
      "epoch: 35, train_loss: 1.5318, test_metric: 0.8836, time: 317.81917691230774\n",
      "epoch: 36, train_loss: 1.5326, test_metric: 0.881, time: 317.9098300933838\n",
      "epoch: 37, train_loss: 1.5301, test_metric: 0.8844, time: 317.7815923690796\n",
      "epoch: 38, train_loss: 1.5309, test_metric: 0.8859, time: 317.9834442138672\n",
      "epoch: 39, train_loss: 1.5293, test_metric: 0.8858, time: 317.9507601261139\n",
      "epoch: 40, train_loss: 1.5286, test_metric: 0.8832, time: 317.8222351074219\n",
      "epoch: 41, train_loss: 1.5266, test_metric: 0.8855, time: 317.73835349082947\n",
      "epoch: 42, train_loss: 1.5263, test_metric: 0.881, time: 317.60666728019714\n",
      "epoch: 43, train_loss: 1.526, test_metric: 0.8796, time: 317.87476801872253\n",
      "epoch: 44, train_loss: 1.5243, test_metric: 0.8841, time: 317.99227023124695\n",
      "epoch: 45, train_loss: 1.5238, test_metric: 0.8835, time: 317.86659812927246\n",
      "epoch: 46, train_loss: 1.525, test_metric: 0.8886, time: 317.78951120376587\n",
      "epoch: 47, train_loss: 1.5236, test_metric: 0.8837, time: 317.85455083847046\n",
      "epoch: 48, train_loss: 1.5221, test_metric: 0.8797, time: 317.6778202056885\n",
      "epoch: 49, train_loss: 1.5213, test_metric: 0.8829, time: 318.1328661441803\n",
      "epoch: 50, train_loss: 1.5206, test_metric: 0.8821, time: 318.02607703208923\n",
      "epoch: 51, train_loss: 1.5209, test_metric: 0.8859, time: 317.7939100265503\n",
      "epoch: 52, train_loss: 1.5187, test_metric: 0.8871, time: 317.7593038082123\n",
      "epoch: 53, train_loss: 1.5207, test_metric: 0.8848, time: 317.88890838623047\n",
      "epoch: 54, train_loss: 1.5183, test_metric: 0.8874, time: 317.5681803226471\n",
      "epoch: 55, train_loss: 1.5192, test_metric: 0.8912, time: 317.69859290122986\n",
      "epoch: 56, train_loss: 1.5181, test_metric: 0.8838, time: 318.1168625354767\n",
      "epoch: 57, train_loss: 1.5169, test_metric: 0.8873, time: 317.78355145454407\n",
      "epoch: 58, train_loss: 1.5173, test_metric: 0.8835, time: 317.8646562099457\n",
      "epoch: 59, train_loss: 1.5171, test_metric: 0.8862, time: 317.51969599723816\n",
      "epoch: 60, train_loss: 1.5061, test_metric: 0.8951, time: 318.02234625816345\n",
      "epoch: 61, train_loss: 1.5004, test_metric: 0.8967, time: 317.5867269039154\n",
      "epoch: 62, train_loss: 1.4981, test_metric: 0.8955, time: 317.72147369384766\n",
      "epoch: 63, train_loss: 1.4986, test_metric: 0.8954, time: 317.929785490036\n",
      "epoch: 64, train_loss: 1.4955, test_metric: 0.8955, time: 317.76903009414673\n",
      "epoch: 65, train_loss: 1.4955, test_metric: 0.8974, time: 317.62534618377686\n",
      "epoch: 66, train_loss: 1.4952, test_metric: 0.898, time: 317.67988324165344\n",
      "epoch: 67, train_loss: 1.4947, test_metric: 0.8956, time: 317.7305717468262\n",
      "epoch: 68, train_loss: 1.4948, test_metric: 0.8971, time: 317.5478820800781\n",
      "epoch: 69, train_loss: 1.4934, test_metric: 0.8954, time: 317.62068152427673\n",
      "epoch: 70, train_loss: 1.494, test_metric: 0.8953, time: 317.7362082004547\n",
      "epoch: 71, train_loss: 1.4924, test_metric: 0.8959, time: 317.75593423843384\n",
      "epoch: 72, train_loss: 1.4922, test_metric: 0.8952, time: 317.6542863845825\n",
      "epoch: 73, train_loss: 1.4923, test_metric: 0.8922, time: 317.6300287246704\n",
      "epoch: 74, train_loss: 1.4915, test_metric: 0.897, time: 317.8214433193207\n",
      "epoch: 75, train_loss: 1.4921, test_metric: 0.8932, time: 317.65146136283875\n",
      "epoch: 76, train_loss: 1.4915, test_metric: 0.8974, time: 317.7678208351135\n",
      "epoch: 77, train_loss: 1.4907, test_metric: 0.896, time: 317.53176856040955\n",
      "epoch: 78, train_loss: 1.4899, test_metric: 0.8973, time: 317.93954849243164\n",
      "epoch: 79, train_loss: 1.4912, test_metric: 0.8985, time: 317.7054750919342\n",
      "epoch: 80, train_loss: 1.4896, test_metric: 0.8936, time: 317.59684133529663\n",
      "epoch: 81, train_loss: 1.4896, test_metric: 0.893, time: 317.70836663246155\n",
      "epoch: 82, train_loss: 1.4906, test_metric: 0.8927, time: 317.890958070755\n",
      "epoch: 83, train_loss: 1.4902, test_metric: 0.8926, time: 317.60116815567017\n",
      "epoch: 84, train_loss: 1.4902, test_metric: 0.8917, time: 317.8565323352814\n",
      "epoch: 85, train_loss: 1.4881, test_metric: 0.8929, time: 317.8826789855957\n",
      "epoch: 86, train_loss: 1.4893, test_metric: 0.8917, time: 317.7947337627411\n",
      "epoch: 87, train_loss: 1.4895, test_metric: 0.895, time: 317.5795202255249\n",
      "epoch: 88, train_loss: 1.4885, test_metric: 0.8911, time: 317.64368891716003\n",
      "epoch: 89, train_loss: 1.4887, test_metric: 0.8914, time: 317.5731477737427\n",
      "epoch: 90, train_loss: 1.483, test_metric: 0.8988, time: 317.7458529472351\n",
      "epoch: 91, train_loss: 1.481, test_metric: 0.8983, time: 318.0072956085205\n",
      "epoch: 92, train_loss: 1.4801, test_metric: 0.8995, time: 319.44237065315247\n",
      "epoch: 93, train_loss: 1.4799, test_metric: 0.9023, time: 318.069846868515\n",
      "epoch: 94, train_loss: 1.4789, test_metric: 0.9, time: 318.3453505039215\n",
      "epoch: 95, train_loss: 1.4792, test_metric: 0.8988, time: 317.6866841316223\n",
      "epoch: 96, train_loss: 1.4795, test_metric: 0.8971, time: 317.5409893989563\n",
      "epoch: 97, train_loss: 1.4793, test_metric: 0.8993, time: 317.5037543773651\n",
      "epoch: 98, train_loss: 1.4785, test_metric: 0.8982, time: 317.59998416900635\n",
      "epoch: 99, train_loss: 1.4787, test_metric: 0.9006, time: 317.6107802391052\n",
      "epoch: 100, train_loss: 1.4781, test_metric: 0.9005, time: 317.5226035118103\n",
      "epoch: 101, train_loss: 1.4779, test_metric: 0.8978, time: 317.43314719200134\n",
      "epoch: 102, train_loss: 1.4778, test_metric: 0.8976, time: 317.66470885276794\n",
      "epoch: 103, train_loss: 1.4784, test_metric: 0.9, time: 317.5208384990692\n",
      "epoch: 104, train_loss: 1.4776, test_metric: 0.9003, time: 317.5584580898285\n",
      "epoch: 105, train_loss: 1.4777, test_metric: 0.8999, time: 318.0051007270813\n",
      "epoch: 106, train_loss: 1.4774, test_metric: 0.8969, time: 317.8183183670044\n",
      "epoch: 107, train_loss: 1.4768, test_metric: 0.9004, time: 317.5128502845764\n",
      "epoch: 108, train_loss: 1.4773, test_metric: 0.8994, time: 317.376341342926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 109, train_loss: 1.4773, test_metric: 0.8959, time: 317.66199350357056\n",
      "epoch: 110, train_loss: 1.4775, test_metric: 0.8982, time: 317.50482988357544\n",
      "epoch: 111, train_loss: 1.4766, test_metric: 0.8958, time: 318.06205224990845\n",
      "epoch: 112, train_loss: 1.4766, test_metric: 0.8983, time: 317.71575808525085\n",
      "epoch: 113, train_loss: 1.4773, test_metric: 0.8957, time: 318.68185448646545\n",
      "epoch: 114, train_loss: 1.4757, test_metric: 0.8984, time: 317.9829523563385\n",
      "epoch: 115, train_loss: 1.476, test_metric: 0.8983, time: 317.66626381874084\n",
      "epoch: 116, train_loss: 1.4763, test_metric: 0.898, time: 318.401243686676\n",
      "epoch: 117, train_loss: 1.4766, test_metric: 0.8989, time: 318.24490189552307\n",
      "epoch: 118, train_loss: 1.4768, test_metric: 0.9005, time: 318.0798223018646\n",
      "epoch: 119, train_loss: 1.476, test_metric: 0.9035, time: 318.16820096969604\n",
      "epoch: 120, train_loss: 1.474, test_metric: 0.901, time: 318.72754669189453\n",
      "epoch: 121, train_loss: 1.4727, test_metric: 0.9016, time: 318.1766674518585\n",
      "epoch: 122, train_loss: 1.4724, test_metric: 0.9021, time: 318.2853331565857\n",
      "epoch: 123, train_loss: 1.4725, test_metric: 0.9022, time: 318.06085300445557\n",
      "epoch: 124, train_loss: 1.4722, test_metric: 0.9021, time: 317.9598903656006\n",
      "epoch: 125, train_loss: 1.4724, test_metric: 0.9013, time: 317.9805574417114\n",
      "epoch: 126, train_loss: 1.4725, test_metric: 0.903, time: 318.1312234401703\n",
      "epoch: 127, train_loss: 1.4725, test_metric: 0.9021, time: 318.11898493766785\n",
      "epoch: 128, train_loss: 1.4721, test_metric: 0.9023, time: 317.79337191581726\n",
      "epoch: 129, train_loss: 1.472, test_metric: 0.8996, time: 317.902379989624\n",
      "epoch: 130, train_loss: 1.4718, test_metric: 0.9024, time: 318.18932723999023\n",
      "epoch: 131, train_loss: 1.4721, test_metric: 0.9025, time: 318.108717918396\n",
      "epoch: 132, train_loss: 1.4718, test_metric: 0.9016, time: 317.8395140171051\n",
      "epoch: 133, train_loss: 1.4719, test_metric: 0.9013, time: 317.8851623535156\n",
      "epoch: 134, train_loss: 1.472, test_metric: 0.9002, time: 317.99957752227783\n",
      "epoch: 135, train_loss: 1.4718, test_metric: 0.9008, time: 318.13278818130493\n",
      "epoch: 136, train_loss: 1.4717, test_metric: 0.9026, time: 317.81211853027344\n",
      "epoch: 137, train_loss: 1.4715, test_metric: 0.9022, time: 318.1576142311096\n",
      "epoch: 138, train_loss: 1.4716, test_metric: 0.9034, time: 318.0513336658478\n",
      "epoch: 139, train_loss: 1.4718, test_metric: 0.9032, time: 317.9350161552429\n",
      "epoch: 140, train_loss: 1.4713, test_metric: 0.9022, time: 318.3141393661499\n",
      "epoch: 141, train_loss: 1.4715, test_metric: 0.8999, time: 318.18458461761475\n",
      "epoch: 142, train_loss: 1.4714, test_metric: 0.9022, time: 317.94425106048584\n",
      "epoch: 143, train_loss: 1.4716, test_metric: 0.9014, time: 318.10784673690796\n",
      "epoch: 144, train_loss: 1.4716, test_metric: 0.904, time: 318.08118200302124\n",
      "epoch: 145, train_loss: 1.4712, test_metric: 0.902, time: 317.8783106803894\n",
      "epoch: 146, train_loss: 1.4716, test_metric: 0.9016, time: 318.4561071395874\n",
      "epoch: 147, train_loss: 1.4712, test_metric: 0.9041, time: 319.5774652957916\n",
      "epoch: 148, train_loss: 1.4713, test_metric: 0.9028, time: 318.89959955215454\n",
      "epoch: 149, train_loss: 1.4708, test_metric: 0.9016, time: 318.65456366539\n",
      "epoch: 150, train_loss: 1.4706, test_metric: 0.903, time: 318.60587191581726\n",
      "epoch: 151, train_loss: 1.47, test_metric: 0.9048, time: 318.87233328819275\n",
      "epoch: 152, train_loss: 1.4699, test_metric: 0.9045, time: 318.62440824508667\n",
      "epoch: 153, train_loss: 1.4695, test_metric: 0.9057, time: 318.70467734336853\n",
      "epoch: 154, train_loss: 1.4697, test_metric: 0.9047, time: 319.02513098716736\n",
      "epoch: 155, train_loss: 1.4695, test_metric: 0.9044, time: 318.88269567489624\n",
      "epoch: 156, train_loss: 1.4696, test_metric: 0.9018, time: 318.71138095855713\n",
      "epoch: 157, train_loss: 1.4696, test_metric: 0.9009, time: 318.3714122772217\n",
      "epoch: 158, train_loss: 1.4693, test_metric: 0.9041, time: 318.7385747432709\n",
      "epoch: 159, train_loss: 1.4694, test_metric: 0.9052, time: 318.43259739875793\n",
      "epoch: 160, train_loss: 1.4697, test_metric: 0.902, time: 318.24233865737915\n",
      "epoch: 161, train_loss: 1.4697, test_metric: 0.9041, time: 318.5274314880371\n",
      "epoch: 162, train_loss: 1.4696, test_metric: 0.9041, time: 318.66928696632385\n",
      "epoch: 163, train_loss: 1.4695, test_metric: 0.9035, time: 318.41670846939087\n",
      "epoch: 164, train_loss: 1.4694, test_metric: 0.9041, time: 318.38738656044006\n",
      "epoch: 165, train_loss: 1.4695, test_metric: 0.9028, time: 318.2025537490845\n",
      "epoch: 166, train_loss: 1.4693, test_metric: 0.9034, time: 317.93420934677124\n",
      "epoch: 167, train_loss: 1.4693, test_metric: 0.9024, time: 317.92306447029114\n",
      "epoch: 168, train_loss: 1.4694, test_metric: 0.9037, time: 318.0252664089203\n",
      "epoch: 169, train_loss: 1.4695, test_metric: 0.904, time: 317.9493627548218\n",
      "epoch: 170, train_loss: 1.4691, test_metric: 0.9036, time: 318.007657289505\n",
      "epoch: 171, train_loss: 1.4693, test_metric: 0.9012, time: 317.8696184158325\n",
      "epoch: 172, train_loss: 1.4691, test_metric: 0.9041, time: 318.1751708984375\n",
      "epoch: 173, train_loss: 1.4694, test_metric: 0.9024, time: 317.88471031188965\n",
      "epoch: 174, train_loss: 1.469, test_metric: 0.9056, time: 317.851904630661\n",
      "epoch: 175, train_loss: 1.4692, test_metric: 0.9029, time: 318.07614970207214\n",
      "epoch: 176, train_loss: 1.4692, test_metric: 0.9044, time: 318.1127288341522\n",
      "epoch: 177, train_loss: 1.4692, test_metric: 0.9017, time: 317.9011752605438\n",
      "epoch: 178, train_loss: 1.4691, test_metric: 0.903, time: 317.8175277709961\n",
      "epoch: 179, train_loss: 1.4693, test_metric: 0.9053, time: 317.988614320755\n",
      "epoch: 180, train_loss: 1.4689, test_metric: 0.9044, time: 318.1495053768158\n",
      "epoch: 181, train_loss: 1.4684, test_metric: 0.9032, time: 318.16005754470825\n",
      "epoch: 182, train_loss: 1.4687, test_metric: 0.9041, time: 318.6391246318817\n",
      "epoch: 183, train_loss: 1.4686, test_metric: 0.9051, time: 318.30945229530334\n",
      "epoch: 184, train_loss: 1.4687, test_metric: 0.9042, time: 318.5741322040558\n",
      "epoch: 185, train_loss: 1.4682, test_metric: 0.9052, time: 318.3939435482025\n",
      "epoch: 186, train_loss: 1.4684, test_metric: 0.904, time: 318.83144068717957\n",
      "epoch: 187, train_loss: 1.4686, test_metric: 0.905, time: 318.23525643348694\n",
      "epoch: 188, train_loss: 1.4684, test_metric: 0.9043, time: 318.2106862068176\n",
      "epoch: 189, train_loss: 1.4684, test_metric: 0.9038, time: 318.4384880065918\n",
      "epoch: 190, train_loss: 1.4682, test_metric: 0.9043, time: 318.430287361145\n",
      "epoch: 191, train_loss: 1.4682, test_metric: 0.9047, time: 318.178683757782\n",
      "epoch: 192, train_loss: 1.4683, test_metric: 0.9017, time: 318.209459066391\n",
      "epoch: 193, train_loss: 1.4684, test_metric: 0.9028, time: 318.6496925354004\n",
      "epoch: 194, train_loss: 1.4684, test_metric: 0.9041, time: 318.40381360054016\n",
      "epoch: 195, train_loss: 1.4682, test_metric: 0.9026, time: 321.826224565506\n",
      "epoch: 196, train_loss: 1.4682, test_metric: 0.9022, time: 319.8028438091278\n",
      "epoch: 197, train_loss: 1.4683, test_metric: 0.9022, time: 318.88243198394775\n",
      "epoch: 198, train_loss: 1.4684, test_metric: 0.9027, time: 319.4757878780365\n",
      "epoch: 199, train_loss: 1.4683, test_metric: 0.9026, time: 318.23258113861084\n",
      "epoch: 200, train_loss: 1.4679, test_metric: 0.9048, time: 464.3377912044525\n",
      "epoch: 201, train_loss: 1.4681, test_metric: 0.9031, time: 385.59745240211487\n",
      "epoch: 202, train_loss: 1.4681, test_metric: 0.9024, time: 411.24405670166016\n",
      "epoch: 203, train_loss: 1.4682, test_metric: 0.9037, time: 387.3331472873688\n",
      "epoch: 204, train_loss: 1.4679, test_metric: 0.901, time: 332.46094965934753\n",
      "epoch: 205, train_loss: 1.4683, test_metric: 0.903, time: 335.9039857387543\n",
      "epoch: 206, train_loss: 1.4679, test_metric: 0.9019, time: 328.91519236564636\n",
      "epoch: 207, train_loss: 1.4681, test_metric: 0.902, time: 323.8780038356781\n",
      "epoch: 208, train_loss: 1.4682, test_metric: 0.902, time: 326.97010040283203\n",
      "epoch: 209, train_loss: 1.468, test_metric: 0.9018, time: 327.44350600242615\n",
      "epoch: 210, train_loss: 1.4681, test_metric: 0.902, time: 329.43793988227844\n",
      "epoch: 211, train_loss: 1.4682, test_metric: 0.9021, time: 319.2871823310852\n",
      "epoch: 212, train_loss: 1.4678, test_metric: 0.9027, time: 319.29219484329224\n",
      "epoch: 213, train_loss: 1.4678, test_metric: 0.9041, time: 319.6218330860138\n",
      "epoch: 214, train_loss: 1.4678, test_metric: 0.9031, time: 319.0529673099518\n",
      "epoch: 215, train_loss: 1.4678, test_metric: 0.9028, time: 319.35108375549316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 216, train_loss: 1.4679, test_metric: 0.9023, time: 318.9922752380371\n",
      "epoch: 217, train_loss: 1.4677, test_metric: 0.9029, time: 319.5867464542389\n",
      "epoch: 218, train_loss: 1.4676, test_metric: 0.9025, time: 319.05059146881104\n",
      "epoch: 219, train_loss: 1.4679, test_metric: 0.9029, time: 319.1204822063446\n",
      "epoch: 220, train_loss: 1.4676, test_metric: 0.9039, time: 320.11825609207153\n",
      "epoch: 221, train_loss: 1.4681, test_metric: 0.9036, time: 319.61707639694214\n",
      "epoch: 222, train_loss: 1.4676, test_metric: 0.9036, time: 319.55531191825867\n",
      "epoch: 223, train_loss: 1.4675, test_metric: 0.9023, time: 319.6396834850311\n",
      "epoch: 224, train_loss: 1.4676, test_metric: 0.9045, time: 319.4268012046814\n",
      "epoch: 225, train_loss: 1.4678, test_metric: 0.902, time: 319.64025807380676\n",
      "epoch: 226, train_loss: 1.4676, test_metric: 0.9032, time: 319.2918527126312\n",
      "epoch: 227, train_loss: 1.4676, test_metric: 0.9028, time: 318.93611574172974\n",
      "epoch: 228, train_loss: 1.4678, test_metric: 0.9037, time: 319.6378242969513\n",
      "epoch: 229, train_loss: 1.4678, test_metric: 0.9046, time: 318.5504608154297\n",
      "epoch: 230, train_loss: 1.4678, test_metric: 0.9035, time: 318.97125577926636\n",
      "epoch: 231, train_loss: 1.4676, test_metric: 0.9041, time: 319.1718316078186\n",
      "epoch: 232, train_loss: 1.4675, test_metric: 0.9038, time: 318.7554018497467\n",
      "epoch: 233, train_loss: 1.4677, test_metric: 0.9031, time: 318.15973472595215\n",
      "epoch: 234, train_loss: 1.4677, test_metric: 0.9035, time: 318.92435002326965\n",
      "epoch: 235, train_loss: 1.4679, test_metric: 0.9026, time: 318.2009205818176\n",
      "epoch: 236, train_loss: 1.4676, test_metric: 0.9021, time: 318.9156656265259\n",
      "epoch: 237, train_loss: 1.4678, test_metric: 0.9025, time: 318.5304582118988\n",
      "epoch: 238, train_loss: 1.4674, test_metric: 0.9027, time: 319.59699845314026\n",
      "epoch: 239, train_loss: 1.4676, test_metric: 0.9027, time: 318.9673402309418\n",
      "epoch: 240, train_loss: 1.4674, test_metric: 0.9008, time: 318.92692494392395\n",
      "epoch: 241, train_loss: 1.4676, test_metric: 0.9019, time: 318.48410844802856\n",
      "epoch: 242, train_loss: 1.4676, test_metric: 0.9045, time: 319.5317783355713\n",
      "epoch: 243, train_loss: 1.4674, test_metric: 0.9026, time: 318.1539475917816\n",
      "epoch: 244, train_loss: 1.4675, test_metric: 0.9026, time: 318.7417073249817\n",
      "epoch: 245, train_loss: 1.4677, test_metric: 0.9029, time: 318.664648771286\n",
      "epoch: 246, train_loss: 1.4676, test_metric: 0.9032, time: 318.8191874027252\n",
      "epoch: 247, train_loss: 1.4674, test_metric: 0.9011, time: 318.7762944698334\n",
      "epoch: 248, train_loss: 1.4677, test_metric: 0.9041, time: 319.0754072666168\n",
      "epoch: 249, train_loss: 1.4674, test_metric: 0.9039, time: 318.70419788360596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<driver.driver.ABC_Driver at 0x7f35aaa19220>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in driver.model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272570"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cifar10_args.layers=[\n",
    "#     ('agnostic', ((input_channel, knpp[0], 9), 1, None, None, activation, False)),\n",
    "#     ('agnostic', ((knpp[0], knpp[0], 9), 2, None, None, activation)),\n",
    "#     ('agnostic', ((knpp[0], knpp[1], 9), 2, None, None, activation)),\n",
    "#     ('agnostic', ((knpp[1], knpp[2], 9), 2, None, None, activation)),\n",
    "#     ('agnostic', ((knpp[2], knpp[3], 9), 2, 'first', (2,2), activation)),\n",
    "#     ('agnostic', ((knpp[3], knpp[4], 9), 2, None, None, activation)),\n",
    "#     ('agnostic', ((knpp[4], knpp[5], 9), 2, None, None, activation)),\n",
    "#     ('agnostic', ((knpp[5], knpp[6], 9), 2, 'first', (2,2), activation)),\n",
    "#     ('agnostic', ((knpp[6], knpp[7], 9), 2, None, None, activation)),\n",
    "#     ('agnostic', ((knpp[7], knpp[8], 9), 2, None, None, activation)),\n",
    "#     ('adptavgpool', (1,1)),\n",
    "#     ('linear', (knpp[-1], 10, (1,2,3))),\n",
    "#     ('softmax', (1))\n",
    "# ]\n",
    "\n",
    "# cifar10_args.layers=[\n",
    "#     ('cnn2d', ((input_channel, knpp[0], (3,3), 1, 1), 1, None, None, activation, False)),\n",
    "#     ('cnn2d', ((knpp[0], knpp[0], (3,3), 1, 1), 2, None, None, activation)),\n",
    "#     ('cnn2d', ((knpp[0], knpp[1], (3,3), 1, 1), 2, None, None, activation)),\n",
    "#     ('cnn2d', ((knpp[1], knpp[2], (3,3), 1, 1), 2, None, None, activation)),\n",
    "#     ('cnn2d', ((knpp[2], knpp[3], (3,3), 1, 1), 2, 'first', (2,2), activation)),\n",
    "#     ('cnn2d', ((knpp[3], knpp[4], (3,3), 1, 1), 2, None, None, activation)),\n",
    "#     ('cnn2d', ((knpp[4], knpp[5], (3,3), 1, 1), 2, None, None, activation)),\n",
    "#     ('cnn2d', ((knpp[5], knpp[6], (3,3), 1, 1), 2, 'first', (2,2), activation)),\n",
    "#     ('cnn2d', ((knpp[6], knpp[7], (3,3), 1, 1), 2, None, None, activation)),\n",
    "#     ('cnn2d', ((knpp[7], knpp[8], (3,3), 1, 1), 2, None, None, activation)),\n",
    "#     ('adptavgpool', (1,1)),\n",
    "#     ('linear', (knpp[-1], 10, (1,2,3))),\n",
    "#     ('softmax', (1))\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[('cnn2d', ((3, 16, (3, 3), 1, 1), 1, None, None, 'relu', False)), \n",
    " ('cnn2d', ((16, 16, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((16, 16, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((16, 16, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((16, 32, (3, 3), 1, 1), 2, 'first', (2, 2), 'relu')), \n",
    " ('cnn2d', ((32, 32, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((32, 32, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((32, 64, (3, 3), 1, 1), 2, 'first', (2, 2), 'relu')), \n",
    " ('cnn2d', ((64, 64, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('cnn2d', ((64, 64, (3, 3), 1, 1), 2, None, None, 'relu')), \n",
    " ('adptavgpool', (1, 1)), \n",
    " ('linear', (64, 10, (1, 2, 3))), \n",
    " ('softmax', 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
