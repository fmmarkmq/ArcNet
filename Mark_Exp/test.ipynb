{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 CNN: 0.98\n",
    "1 CNN: 0.9615 epoch 3\n",
    "1 CNN: 0.9782 epoch 50\n",
    "ABC: 0.9575 batch 100, lr 0.0001, metrics criterion 'CE', epoch 3\n",
    "ABC: 0.9671 batch 100, lr 0.0001, metrics criterion 'CE', epoch 6\n",
    "ABC: 0.9768 epoch 50 kernel_per_pixel 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.tools import dotdict\n",
    "from driver.driver import ABC_Driver\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.set_device(0)\n",
    "import atd2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_args = dotdict()\n",
    "mnist_args.train = dotdict()\n",
    "mnist_args.predict = dotdict()\n",
    "\n",
    "mnist_args.name = 'mnist'\n",
    "mnist_args.train.batch_size = 60\n",
    "mnist_args.predict.batch_size = 1000\n",
    "\n",
    "mnist_args.train_epochs= 3\n",
    "mnist_args.lr = 0.0001\n",
    "mnist_args.criterion = 'CE'\n",
    "mnist_args.use_gpu = True\n",
    "\n",
    "mnist_args.input_channel = 1\n",
    "mnist_args.input_height = 28\n",
    "mnist_args.input_width = 28\n",
    "mnist_args.kernel_size = 9\n",
    "mnist_args.knpp = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "atd_args = dotdict()\n",
    "atd_args.train = dotdict()\n",
    "\n",
    "atd_args.name = 'atd'\n",
    "atd_args.train.batch_size = 30\n",
    "atd_args.predict_len = 1\n",
    "atd_args.history_len = 2\n",
    "\n",
    "atd_args.train_epochs= 500\n",
    "atd_args.lr = 0.01\n",
    "atd_args.criterion = 'L1'\n",
    "atd_args.use_gpu = True\n",
    "\n",
    "atd_args.input_channel = atd_args.history_len\n",
    "atd_args.input_height = 1\n",
    "atd_args.input_width = 5200\n",
    "atd_args.kernel_size = 10\n",
    "atd_args.knpp = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:None\n",
      "epoch: 0, train_loss: 185387.02673339844\n",
      "epoch: 1, train_loss: 67457.7373046875\n",
      "epoch: 2, train_loss: 53555.68212890625\n",
      "epoch: 3, train_loss: 28414.289184570312\n",
      "epoch: 4, train_loss: 16215.845703125\n",
      "epoch: 5, train_loss: 12908.164916992188\n",
      "epoch: 6, train_loss: 12592.016845703125\n",
      "epoch: 7, train_loss: 8057.8001708984375\n",
      "epoch: 8, train_loss: 6691.250427246094\n",
      "epoch: 9, train_loss: 5188.834228515625\n",
      "epoch: 10, train_loss: 4200.933197021484\n",
      "epoch: 11, train_loss: 3392.992218017578\n",
      "epoch: 12, train_loss: 2820.3392944335938\n",
      "epoch: 13, train_loss: 2315.4476470947266\n",
      "epoch: 14, train_loss: 1966.7245178222656\n",
      "epoch: 15, train_loss: 1639.0831909179688\n",
      "epoch: 16, train_loss: 1384.4906311035156\n",
      "epoch: 17, train_loss: 1155.9023361206055\n",
      "epoch: 18, train_loss: 1003.4671096801758\n",
      "epoch: 19, train_loss: 869.5424652099609\n",
      "epoch: 20, train_loss: 780.389289855957\n",
      "epoch: 21, train_loss: 679.0180587768555\n",
      "epoch: 22, train_loss: 629.3713836669922\n",
      "epoch: 23, train_loss: 554.0561485290527\n",
      "epoch: 24, train_loss: 560.2323341369629\n",
      "epoch: 25, train_loss: 480.9261779785156\n",
      "epoch: 26, train_loss: 448.4446029663086\n",
      "epoch: 27, train_loss: 396.6446533203125\n",
      "epoch: 28, train_loss: 357.3917579650879\n",
      "epoch: 29, train_loss: 334.01458740234375\n",
      "epoch: 30, train_loss: 307.5873107910156\n",
      "epoch: 31, train_loss: 285.0269775390625\n",
      "epoch: 32, train_loss: 262.3699188232422\n",
      "epoch: 33, train_loss: 257.3529529571533\n",
      "epoch: 34, train_loss: 243.70035934448242\n",
      "epoch: 35, train_loss: 236.1012363433838\n",
      "epoch: 36, train_loss: 222.2228012084961\n",
      "epoch: 37, train_loss: 209.27947521209717\n",
      "epoch: 38, train_loss: 206.23108100891113\n",
      "epoch: 39, train_loss: 196.47075843811035\n",
      "epoch: 40, train_loss: 189.96606063842773\n",
      "epoch: 41, train_loss: 185.3216257095337\n",
      "epoch: 42, train_loss: 178.32552528381348\n",
      "epoch: 43, train_loss: 172.04246711730957\n",
      "epoch: 44, train_loss: 169.48959350585938\n",
      "epoch: 45, train_loss: 164.9460096359253\n",
      "epoch: 46, train_loss: 160.85265254974365\n",
      "epoch: 47, train_loss: 157.76791667938232\n",
      "epoch: 48, train_loss: 154.5496187210083\n",
      "epoch: 49, train_loss: 148.8856325149536\n",
      "epoch: 50, train_loss: 146.3761854171753\n",
      "epoch: 51, train_loss: 142.81872463226318\n",
      "epoch: 52, train_loss: 143.83989238739014\n",
      "epoch: 53, train_loss: 138.0899658203125\n",
      "epoch: 54, train_loss: 138.92351722717285\n",
      "epoch: 55, train_loss: 135.13412761688232\n",
      "epoch: 56, train_loss: 132.11735343933105\n",
      "epoch: 57, train_loss: 128.90417385101318\n",
      "epoch: 58, train_loss: 133.4796257019043\n",
      "epoch: 59, train_loss: 128.02007579803467\n",
      "epoch: 60, train_loss: 127.25255107879639\n",
      "epoch: 61, train_loss: 127.2321195602417\n",
      "epoch: 62, train_loss: 124.72996520996094\n",
      "epoch: 63, train_loss: 122.31142520904541\n",
      "epoch: 64, train_loss: 120.66328430175781\n",
      "epoch: 65, train_loss: 117.52707195281982\n",
      "epoch: 66, train_loss: 115.3098030090332\n",
      "epoch: 67, train_loss: 118.05926990509033\n",
      "epoch: 68, train_loss: 113.01190662384033\n",
      "epoch: 69, train_loss: 110.30063438415527\n",
      "epoch: 70, train_loss: 114.32720375061035\n",
      "epoch: 71, train_loss: 110.37569332122803\n",
      "epoch: 72, train_loss: 109.08681440353394\n",
      "epoch: 73, train_loss: 111.65790843963623\n",
      "epoch: 74, train_loss: 107.28651857376099\n",
      "epoch: 75, train_loss: 104.86322116851807\n",
      "epoch: 76, train_loss: 106.03289699554443\n",
      "epoch: 77, train_loss: 103.21532344818115\n",
      "epoch: 78, train_loss: 104.27475929260254\n",
      "epoch: 79, train_loss: 102.73787021636963\n",
      "epoch: 80, train_loss: 102.71537446975708\n",
      "epoch: 81, train_loss: 101.19236993789673\n",
      "epoch: 82, train_loss: 100.62868785858154\n",
      "epoch: 83, train_loss: 98.65141582489014\n",
      "epoch: 84, train_loss: 98.59165859222412\n",
      "epoch: 85, train_loss: 97.77916049957275\n",
      "epoch: 86, train_loss: 96.84279155731201\n",
      "epoch: 87, train_loss: 98.33106660842896\n",
      "epoch: 88, train_loss: 95.85705852508545\n",
      "epoch: 89, train_loss: 93.86009740829468\n",
      "epoch: 90, train_loss: 91.99096727371216\n",
      "epoch: 91, train_loss: 93.43024730682373\n",
      "epoch: 92, train_loss: 92.41917037963867\n",
      "epoch: 93, train_loss: 90.43272066116333\n",
      "epoch: 94, train_loss: 97.92803239822388\n",
      "epoch: 95, train_loss: 88.14846086502075\n",
      "epoch: 96, train_loss: 87.60604906082153\n",
      "epoch: 97, train_loss: 87.12911081314087\n",
      "epoch: 98, train_loss: 89.62241840362549\n",
      "epoch: 99, train_loss: 87.5464358329773\n",
      "epoch: 100, train_loss: 92.34926414489746\n",
      "epoch: 101, train_loss: 84.9297866821289\n",
      "epoch: 102, train_loss: 84.62261199951172\n",
      "epoch: 103, train_loss: 87.14965438842773\n",
      "epoch: 104, train_loss: 90.34750699996948\n",
      "epoch: 105, train_loss: 87.8870677947998\n",
      "epoch: 106, train_loss: 83.2836766242981\n",
      "epoch: 107, train_loss: 85.04731321334839\n",
      "epoch: 108, train_loss: 87.23408365249634\n",
      "epoch: 109, train_loss: 81.08475923538208\n",
      "epoch: 110, train_loss: 82.61250925064087\n",
      "epoch: 111, train_loss: 82.88469076156616\n",
      "epoch: 112, train_loss: 79.7844443321228\n",
      "epoch: 113, train_loss: 83.85875511169434\n",
      "epoch: 114, train_loss: 82.32556200027466\n",
      "epoch: 115, train_loss: 83.21550416946411\n",
      "epoch: 116, train_loss: 77.73773717880249\n",
      "epoch: 117, train_loss: 78.9415545463562\n",
      "epoch: 118, train_loss: 81.07881164550781\n",
      "epoch: 119, train_loss: 75.99294948577881\n",
      "epoch: 120, train_loss: 79.11414003372192\n",
      "epoch: 121, train_loss: 78.44897365570068\n",
      "epoch: 122, train_loss: 81.47931671142578\n",
      "epoch: 123, train_loss: 75.93190622329712\n",
      "epoch: 124, train_loss: 77.63930654525757\n",
      "epoch: 125, train_loss: 79.26086378097534\n",
      "epoch: 126, train_loss: 75.27930068969727\n",
      "epoch: 127, train_loss: 72.67278528213501\n",
      "epoch: 128, train_loss: 75.1347827911377\n",
      "epoch: 129, train_loss: 73.888596534729\n",
      "epoch: 130, train_loss: 78.24579524993896\n",
      "epoch: 131, train_loss: 73.79736471176147\n",
      "epoch: 132, train_loss: 68.72492694854736\n",
      "epoch: 133, train_loss: 73.37482643127441\n",
      "epoch: 134, train_loss: 70.06201362609863\n",
      "epoch: 135, train_loss: 77.22983264923096\n",
      "epoch: 136, train_loss: 76.28729152679443\n",
      "epoch: 137, train_loss: 69.69546365737915\n",
      "epoch: 138, train_loss: 76.68399715423584\n",
      "epoch: 139, train_loss: 69.96215629577637\n",
      "epoch: 140, train_loss: 69.25766563415527\n",
      "epoch: 141, train_loss: 70.3187689781189\n",
      "epoch: 142, train_loss: 73.49613380432129\n",
      "epoch: 143, train_loss: 73.19640684127808\n",
      "epoch: 144, train_loss: 68.0178484916687\n",
      "epoch: 145, train_loss: 74.21312665939331\n",
      "epoch: 146, train_loss: 67.49983406066895\n",
      "epoch: 147, train_loss: 66.91346645355225\n",
      "epoch: 148, train_loss: 68.60857820510864\n",
      "epoch: 149, train_loss: 71.7352123260498\n",
      "epoch: 150, train_loss: 71.68952369689941\n",
      "epoch: 151, train_loss: 64.64961290359497\n",
      "epoch: 152, train_loss: 72.70504856109619\n",
      "epoch: 153, train_loss: 65.42547988891602\n",
      "epoch: 154, train_loss: 65.99845457077026\n",
      "epoch: 155, train_loss: 66.13000154495239\n",
      "epoch: 156, train_loss: 70.64960956573486\n",
      "epoch: 157, train_loss: 69.40063762664795\n",
      "epoch: 158, train_loss: 60.76655721664429\n",
      "epoch: 159, train_loss: 67.73534393310547\n",
      "epoch: 160, train_loss: 63.308207511901855\n",
      "epoch: 161, train_loss: 64.64376592636108\n",
      "epoch: 162, train_loss: 62.893738746643066\n",
      "epoch: 163, train_loss: 70.34075832366943\n",
      "epoch: 164, train_loss: 67.22702550888062\n",
      "epoch: 165, train_loss: 59.660221099853516\n",
      "epoch: 166, train_loss: 65.16934204101562\n",
      "epoch: 167, train_loss: 64.22455263137817\n",
      "epoch: 168, train_loss: 64.81576347351074\n",
      "epoch: 169, train_loss: 67.88602113723755\n",
      "epoch: 170, train_loss: 59.805511474609375\n",
      "epoch: 171, train_loss: 59.98940658569336\n",
      "epoch: 172, train_loss: 63.42150688171387\n",
      "epoch: 173, train_loss: 60.5379319190979\n",
      "epoch: 174, train_loss: 61.67303276062012\n",
      "epoch: 175, train_loss: 60.768086433410645\n",
      "epoch: 176, train_loss: 68.39026165008545\n",
      "epoch: 177, train_loss: 62.21586561203003\n",
      "epoch: 178, train_loss: 57.72882795333862\n",
      "epoch: 179, train_loss: 65.83783102035522\n",
      "epoch: 180, train_loss: 57.952261447906494\n",
      "epoch: 181, train_loss: 57.989909172058105\n",
      "epoch: 182, train_loss: 60.87738513946533\n",
      "epoch: 183, train_loss: 62.42017126083374\n",
      "epoch: 184, train_loss: 64.47735214233398\n",
      "epoch: 185, train_loss: 56.31325674057007\n",
      "epoch: 186, train_loss: 63.97310447692871\n",
      "epoch: 187, train_loss: 56.18919372558594\n",
      "epoch: 188, train_loss: 55.49363374710083\n",
      "epoch: 189, train_loss: 57.376264572143555\n",
      "epoch: 190, train_loss: 66.81324815750122\n",
      "epoch: 191, train_loss: 60.97477912902832\n",
      "epoch: 192, train_loss: 55.45149087905884\n",
      "epoch: 193, train_loss: 62.14536809921265\n",
      "epoch: 194, train_loss: 59.526527881622314\n",
      "epoch: 195, train_loss: 54.14776086807251\n",
      "epoch: 196, train_loss: 58.88005065917969\n",
      "epoch: 197, train_loss: 56.37187671661377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 198, train_loss: 58.19011211395264\n",
      "epoch: 199, train_loss: 55.85291576385498\n",
      "epoch: 200, train_loss: 61.70358943939209\n",
      "epoch: 201, train_loss: 53.60595703125\n",
      "epoch: 202, train_loss: 54.482884883880615\n",
      "epoch: 203, train_loss: 54.13412952423096\n",
      "epoch: 204, train_loss: 62.79181146621704\n",
      "epoch: 205, train_loss: 55.779242515563965\n",
      "epoch: 206, train_loss: 52.42071771621704\n",
      "epoch: 207, train_loss: 55.63544034957886\n",
      "epoch: 208, train_loss: 57.88225698471069\n",
      "epoch: 209, train_loss: 58.23936605453491\n",
      "epoch: 210, train_loss: 53.41038131713867\n",
      "epoch: 211, train_loss: 58.87883758544922\n",
      "epoch: 212, train_loss: 53.51545763015747\n",
      "epoch: 213, train_loss: 54.86611604690552\n",
      "epoch: 214, train_loss: 54.57124662399292\n",
      "epoch: 215, train_loss: 60.46696996688843\n",
      "epoch: 216, train_loss: 51.41013145446777\n",
      "epoch: 217, train_loss: 52.64973449707031\n",
      "epoch: 218, train_loss: 54.67036581039429\n",
      "epoch: 219, train_loss: 52.71439027786255\n",
      "epoch: 220, train_loss: 53.27168130874634\n",
      "epoch: 221, train_loss: 54.764434814453125\n",
      "epoch: 222, train_loss: 57.67460632324219\n",
      "epoch: 223, train_loss: 50.812867641448975\n",
      "epoch: 224, train_loss: 50.385435581207275\n",
      "epoch: 225, train_loss: 53.48794984817505\n",
      "epoch: 226, train_loss: 53.59862232208252\n",
      "epoch: 227, train_loss: 53.316701889038086\n",
      "epoch: 228, train_loss: 49.77022361755371\n",
      "epoch: 229, train_loss: 54.748323917388916\n",
      "epoch: 230, train_loss: 48.86907386779785\n",
      "epoch: 231, train_loss: 49.05079889297485\n",
      "epoch: 232, train_loss: 49.984572410583496\n",
      "epoch: 233, train_loss: 57.676339626312256\n",
      "epoch: 234, train_loss: 48.03032684326172\n",
      "epoch: 235, train_loss: 47.863667011260986\n",
      "epoch: 236, train_loss: 48.979191303253174\n",
      "epoch: 237, train_loss: 56.21984100341797\n",
      "epoch: 238, train_loss: 53.52255201339722\n",
      "epoch: 239, train_loss: 47.1605544090271\n",
      "epoch: 240, train_loss: 52.110973834991455\n",
      "epoch: 241, train_loss: 47.996068477630615\n",
      "epoch: 242, train_loss: 50.49927520751953\n",
      "epoch: 243, train_loss: 47.231953382492065\n",
      "epoch: 244, train_loss: 54.77639102935791\n",
      "epoch: 245, train_loss: 50.77927350997925\n",
      "epoch: 246, train_loss: 47.48129320144653\n",
      "epoch: 247, train_loss: 48.67560815811157\n",
      "epoch: 248, train_loss: 51.228819370269775\n",
      "epoch: 249, train_loss: 53.818732261657715\n",
      "epoch: 250, train_loss: 44.886374711990356\n",
      "epoch: 251, train_loss: 47.86084604263306\n",
      "epoch: 252, train_loss: 50.282270431518555\n",
      "epoch: 253, train_loss: 52.712077140808105\n",
      "epoch: 254, train_loss: 45.320051193237305\n",
      "epoch: 255, train_loss: 45.27154588699341\n",
      "epoch: 256, train_loss: 46.77895498275757\n",
      "epoch: 257, train_loss: 51.22262382507324\n",
      "epoch: 258, train_loss: 47.186405658721924\n",
      "epoch: 259, train_loss: 51.93147802352905\n",
      "epoch: 260, train_loss: 46.22234606742859\n",
      "epoch: 261, train_loss: 49.0011043548584\n",
      "epoch: 262, train_loss: 48.19599676132202\n",
      "epoch: 263, train_loss: 45.94387435913086\n",
      "epoch: 264, train_loss: 46.1928915977478\n",
      "epoch: 265, train_loss: 43.75522804260254\n",
      "epoch: 266, train_loss: 45.35031270980835\n",
      "epoch: 267, train_loss: 48.95745611190796\n",
      "epoch: 268, train_loss: 53.2146430015564\n",
      "epoch: 269, train_loss: 43.86426115036011\n",
      "epoch: 270, train_loss: 41.76446294784546\n",
      "epoch: 271, train_loss: 51.926995277404785\n",
      "epoch: 272, train_loss: 53.33747959136963\n",
      "epoch: 273, train_loss: 41.1283483505249\n",
      "epoch: 274, train_loss: 43.31512975692749\n",
      "epoch: 275, train_loss: 44.785016775131226\n",
      "epoch: 276, train_loss: 51.635809898376465\n",
      "epoch: 277, train_loss: 46.02872085571289\n",
      "epoch: 278, train_loss: 47.22789192199707\n",
      "epoch: 279, train_loss: 43.59555244445801\n",
      "epoch: 280, train_loss: 46.213993072509766\n",
      "epoch: 281, train_loss: 45.40639543533325\n",
      "epoch: 282, train_loss: 48.73778247833252\n",
      "epoch: 283, train_loss: 46.1412091255188\n",
      "epoch: 284, train_loss: 43.5819046497345\n",
      "epoch: 285, train_loss: 44.06851291656494\n",
      "epoch: 286, train_loss: 47.067978382110596\n",
      "epoch: 287, train_loss: 50.47833204269409\n",
      "epoch: 288, train_loss: 42.98130798339844\n",
      "epoch: 289, train_loss: 44.53029823303223\n",
      "epoch: 290, train_loss: 49.32109212875366\n",
      "epoch: 291, train_loss: 48.25213575363159\n",
      "epoch: 292, train_loss: 40.48312568664551\n",
      "epoch: 293, train_loss: 43.18387508392334\n",
      "epoch: 294, train_loss: 44.1580548286438\n",
      "epoch: 295, train_loss: 48.52638483047485\n",
      "epoch: 296, train_loss: 42.632330894470215\n",
      "epoch: 297, train_loss: 44.76162147521973\n",
      "epoch: 298, train_loss: 43.90853977203369\n",
      "epoch: 299, train_loss: 45.60975790023804\n",
      "epoch: 300, train_loss: 41.613162994384766\n",
      "epoch: 301, train_loss: 44.39270567893982\n",
      "epoch: 302, train_loss: 42.81162786483765\n",
      "epoch: 303, train_loss: 42.49205827713013\n",
      "epoch: 304, train_loss: 40.1068639755249\n",
      "epoch: 305, train_loss: 45.40461015701294\n",
      "epoch: 306, train_loss: 42.75590944290161\n",
      "epoch: 307, train_loss: 43.2876238822937\n",
      "epoch: 308, train_loss: 39.992467403411865\n",
      "epoch: 309, train_loss: 42.681397914886475\n",
      "epoch: 310, train_loss: 41.96683311462402\n",
      "epoch: 311, train_loss: 44.25517463684082\n",
      "epoch: 312, train_loss: 39.91154646873474\n",
      "epoch: 313, train_loss: 43.9328191280365\n",
      "epoch: 314, train_loss: 46.46940755844116\n",
      "epoch: 315, train_loss: 42.850157737731934\n",
      "epoch: 316, train_loss: 41.54745817184448\n",
      "epoch: 317, train_loss: 42.710147857666016\n",
      "epoch: 318, train_loss: 43.87990093231201\n",
      "epoch: 319, train_loss: 39.07316470146179\n",
      "epoch: 320, train_loss: 39.82640981674194\n",
      "epoch: 321, train_loss: 43.511568784713745\n",
      "epoch: 322, train_loss: 48.55886125564575\n",
      "epoch: 323, train_loss: 36.89729022979736\n",
      "epoch: 324, train_loss: 35.96519613265991\n",
      "epoch: 325, train_loss: 41.50938272476196\n",
      "epoch: 326, train_loss: 44.019773960113525\n",
      "epoch: 327, train_loss: 38.23167586326599\n",
      "epoch: 328, train_loss: 42.53115653991699\n",
      "epoch: 329, train_loss: 42.865543842315674\n",
      "epoch: 330, train_loss: 43.77548027038574\n",
      "epoch: 331, train_loss: 39.361329555511475\n",
      "epoch: 332, train_loss: 42.903708934783936\n",
      "epoch: 333, train_loss: 42.22926473617554\n",
      "epoch: 334, train_loss: 43.845011711120605\n",
      "epoch: 335, train_loss: 37.49894881248474\n",
      "epoch: 336, train_loss: 41.313122272491455\n",
      "epoch: 337, train_loss: 41.581644773483276\n",
      "epoch: 338, train_loss: 42.58570098876953\n",
      "epoch: 339, train_loss: 37.414254665374756\n",
      "epoch: 340, train_loss: 43.193912982940674\n",
      "epoch: 341, train_loss: 40.10056972503662\n",
      "epoch: 342, train_loss: 39.778932094573975\n",
      "epoch: 343, train_loss: 37.89461541175842\n",
      "epoch: 344, train_loss: 44.54558610916138\n",
      "epoch: 345, train_loss: 38.62888693809509\n",
      "epoch: 346, train_loss: 37.90587520599365\n",
      "epoch: 347, train_loss: 38.64732003211975\n",
      "epoch: 348, train_loss: 41.061726093292236\n",
      "epoch: 349, train_loss: 38.480947732925415\n",
      "epoch: 350, train_loss: 40.71667718887329\n",
      "epoch: 351, train_loss: 39.930734157562256\n",
      "epoch: 352, train_loss: 40.77320098876953\n",
      "epoch: 353, train_loss: 42.83045530319214\n",
      "epoch: 354, train_loss: 38.07927346229553\n",
      "epoch: 355, train_loss: 40.24747657775879\n",
      "epoch: 356, train_loss: 40.67057776451111\n",
      "epoch: 357, train_loss: 39.854576110839844\n",
      "epoch: 358, train_loss: 35.53028607368469\n",
      "epoch: 359, train_loss: 39.56526565551758\n",
      "epoch: 360, train_loss: 38.07060885429382\n",
      "epoch: 361, train_loss: 43.938761711120605\n",
      "epoch: 362, train_loss: 37.1637806892395\n",
      "epoch: 363, train_loss: 37.46206712722778\n",
      "epoch: 364, train_loss: 39.39997434616089\n",
      "epoch: 365, train_loss: 39.85766291618347\n",
      "epoch: 366, train_loss: 38.644304275512695\n",
      "epoch: 367, train_loss: 36.541130781173706\n",
      "epoch: 368, train_loss: 36.97734808921814\n",
      "epoch: 369, train_loss: 40.42535877227783\n",
      "epoch: 370, train_loss: 40.66469407081604\n",
      "epoch: 371, train_loss: 38.7148540019989\n",
      "epoch: 372, train_loss: 37.43135952949524\n",
      "epoch: 373, train_loss: 40.71406078338623\n",
      "epoch: 374, train_loss: 37.522292613983154\n",
      "epoch: 375, train_loss: 40.84161424636841\n",
      "epoch: 376, train_loss: 38.09128785133362\n",
      "epoch: 377, train_loss: 38.47747206687927\n",
      "epoch: 378, train_loss: 37.42306351661682\n",
      "epoch: 379, train_loss: 42.862205505371094\n",
      "epoch: 380, train_loss: 37.86525082588196\n",
      "epoch: 381, train_loss: 36.786006450653076\n",
      "epoch: 382, train_loss: 36.3106575012207\n",
      "epoch: 383, train_loss: 39.56321954727173\n",
      "epoch: 384, train_loss: 36.31224036216736\n",
      "epoch: 385, train_loss: 39.47299933433533\n",
      "epoch: 386, train_loss: 35.12606191635132\n",
      "epoch: 387, train_loss: 38.57851719856262\n",
      "epoch: 388, train_loss: 38.927274227142334\n",
      "epoch: 389, train_loss: 39.19306302070618\n",
      "epoch: 390, train_loss: 37.9965238571167\n",
      "epoch: 391, train_loss: 35.94432783126831\n",
      "epoch: 392, train_loss: 35.63928556442261\n",
      "epoch: 393, train_loss: 36.8741500377655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 394, train_loss: 39.44849920272827\n",
      "epoch: 395, train_loss: 37.64045524597168\n",
      "epoch: 396, train_loss: 40.18035840988159\n",
      "epoch: 397, train_loss: 35.79669451713562\n",
      "epoch: 398, train_loss: 37.38870668411255\n",
      "epoch: 399, train_loss: 37.04893779754639\n",
      "epoch: 400, train_loss: 39.28644680976868\n",
      "epoch: 401, train_loss: 35.92985939979553\n",
      "epoch: 402, train_loss: 37.30841112136841\n",
      "epoch: 403, train_loss: 37.09222912788391\n",
      "epoch: 404, train_loss: 37.94956731796265\n",
      "epoch: 405, train_loss: 38.821826457977295\n",
      "epoch: 406, train_loss: 34.67558836936951\n",
      "epoch: 407, train_loss: 37.043763160705566\n",
      "epoch: 408, train_loss: 34.40589618682861\n",
      "epoch: 409, train_loss: 36.538894176483154\n",
      "epoch: 410, train_loss: 34.860113859176636\n",
      "epoch: 411, train_loss: 42.15435600280762\n",
      "epoch: 412, train_loss: 35.548370122909546\n",
      "epoch: 413, train_loss: 35.361693382263184\n",
      "epoch: 414, train_loss: 33.5046489238739\n",
      "epoch: 415, train_loss: 38.984294414520264\n",
      "epoch: 416, train_loss: 36.06252956390381\n",
      "epoch: 417, train_loss: 37.09044599533081\n",
      "epoch: 418, train_loss: 35.16237497329712\n",
      "epoch: 419, train_loss: 37.60589241981506\n",
      "epoch: 420, train_loss: 35.067304611206055\n",
      "epoch: 421, train_loss: 38.91422128677368\n",
      "epoch: 422, train_loss: 39.96644163131714\n",
      "epoch: 423, train_loss: 32.407756090164185\n",
      "epoch: 424, train_loss: 36.285343647003174\n",
      "epoch: 425, train_loss: 38.35734224319458\n",
      "epoch: 426, train_loss: 40.40783452987671\n",
      "epoch: 427, train_loss: 31.275001049041748\n",
      "epoch: 428, train_loss: 33.52851629257202\n",
      "epoch: 429, train_loss: 34.88517761230469\n",
      "epoch: 430, train_loss: 38.71393537521362\n",
      "epoch: 431, train_loss: 36.34462237358093\n",
      "epoch: 432, train_loss: 34.10055112838745\n",
      "epoch: 433, train_loss: 32.49946355819702\n",
      "epoch: 434, train_loss: 37.489376068115234\n",
      "epoch: 435, train_loss: 34.1161904335022\n",
      "epoch: 436, train_loss: 34.37361264228821\n",
      "epoch: 437, train_loss: 32.93986201286316\n",
      "epoch: 438, train_loss: 38.00347423553467\n",
      "epoch: 439, train_loss: 34.265647649765015\n",
      "epoch: 440, train_loss: 33.29862713813782\n",
      "epoch: 441, train_loss: 32.13484501838684\n",
      "epoch: 442, train_loss: 37.11909627914429\n",
      "epoch: 443, train_loss: 35.97627091407776\n",
      "epoch: 444, train_loss: 32.52385234832764\n",
      "epoch: 445, train_loss: 31.181846380233765\n",
      "epoch: 446, train_loss: 32.279545307159424\n",
      "epoch: 447, train_loss: 34.199567794799805\n",
      "epoch: 448, train_loss: 39.34083938598633\n",
      "epoch: 449, train_loss: 37.55392098426819\n",
      "epoch: 450, train_loss: 32.57278871536255\n",
      "epoch: 451, train_loss: 32.90757155418396\n",
      "epoch: 452, train_loss: 38.36907410621643\n",
      "epoch: 453, train_loss: 40.97961187362671\n",
      "epoch: 454, train_loss: 29.596155643463135\n",
      "epoch: 455, train_loss: 29.00501585006714\n",
      "epoch: 456, train_loss: 34.16865086555481\n",
      "epoch: 457, train_loss: 40.331517934799194\n",
      "epoch: 458, train_loss: 32.279462814331055\n",
      "epoch: 459, train_loss: 32.16958737373352\n",
      "epoch: 460, train_loss: 38.787532329559326\n",
      "epoch: 461, train_loss: 38.51635694503784\n",
      "epoch: 462, train_loss: 29.225921630859375\n",
      "epoch: 463, train_loss: 31.60741353034973\n",
      "epoch: 464, train_loss: 33.646584272384644\n",
      "epoch: 465, train_loss: 39.57858610153198\n",
      "epoch: 466, train_loss: 31.39824938774109\n",
      "epoch: 467, train_loss: 31.785878658294678\n",
      "epoch: 468, train_loss: 33.031694412231445\n",
      "epoch: 469, train_loss: 35.8018274307251\n",
      "epoch: 470, train_loss: 30.902003526687622\n",
      "epoch: 471, train_loss: 32.632169246673584\n",
      "epoch: 472, train_loss: 31.59834361076355\n",
      "epoch: 473, train_loss: 39.60869646072388\n",
      "epoch: 474, train_loss: 32.23859119415283\n",
      "epoch: 475, train_loss: 29.7071316242218\n",
      "epoch: 476, train_loss: 29.665942430496216\n",
      "epoch: 477, train_loss: 32.78911995887756\n",
      "epoch: 478, train_loss: 38.822335720062256\n",
      "epoch: 479, train_loss: 45.609906911849976\n",
      "epoch: 480, train_loss: 34.27819108963013\n",
      "epoch: 481, train_loss: 29.32506251335144\n",
      "epoch: 482, train_loss: 28.709915161132812\n",
      "epoch: 483, train_loss: 32.00541424751282\n",
      "epoch: 484, train_loss: 35.07764983177185\n",
      "epoch: 485, train_loss: 37.09439206123352\n",
      "epoch: 486, train_loss: 34.62448763847351\n",
      "epoch: 487, train_loss: 33.818199157714844\n",
      "epoch: 488, train_loss: 34.435765743255615\n",
      "epoch: 489, train_loss: 34.614296197891235\n",
      "epoch: 490, train_loss: 37.866278648376465\n",
      "epoch: 491, train_loss: 32.84047484397888\n",
      "epoch: 492, train_loss: 34.75798320770264\n",
      "epoch: 493, train_loss: 32.70034885406494\n",
      "epoch: 494, train_loss: 35.37640571594238\n",
      "epoch: 495, train_loss: 31.388978958129883\n",
      "epoch: 496, train_loss: 33.6406991481781\n",
      "epoch: 497, train_loss: 32.623080015182495\n",
      "epoch: 498, train_loss: 35.843568325042725\n",
      "epoch: 499, train_loss: 30.6812264919281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<driver.driver.ABC_Driver at 0x7f7dd0b6eac0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = atd_args\n",
    "data = atd2022.io.read_csv()\n",
    "# data = None\n",
    "driver = ABC_Driver(args, data)\n",
    "driver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-40.,   1., -41.,  ..., -11., -69., -29.]]],\n",
       "\n",
       "\n",
       "        [[[ 14., -36., -15.,  ...,  23.,  32.,  30.]]],\n",
       "\n",
       "\n",
       "        [[[  7., -26.,  40.,  ...,  30.,  -3.,  39.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 13.,   0., -23.,  ..., 116., 185.,  57.]]],\n",
       "\n",
       "\n",
       "        [[[ 25., -34., -35.,  ...,  42., 140.,  62.]]],\n",
       "\n",
       "\n",
       "        [[[  0., -33., -12.,  ..., 143., 135.,  55.]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = driver.predict(driver.data_loader.train).to(float).round()\n",
    "train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-11.0284,  -0.2645,  26.7892,  ..., 162.1727,  83.6228,  42.1392]]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = driver.predict().to(float)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  7.7031,   2.9904,   3.4786,  ...,  80.0183, 205.7635,   0.0000]],\n",
       "\n",
       "         [[ 10.1797,   1.5562,   3.0605,  ...,  76.9034, 209.3571,   0.0000]],\n",
       "\n",
       "         [[  7.8379,   2.6050,   3.5921,  ...,  77.9101, 224.6351,   0.0000]],\n",
       "\n",
       "         [[  8.1780,   2.4698,   3.5343,  ...,  75.4261, 224.9489,   0.0000]]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = driver.predict().to(float)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region  Event\n",
       "AA      01        10.474419\n",
       "        02         4.139535\n",
       "        03         7.246512\n",
       "        04        24.525581\n",
       "        05         5.079070\n",
       "                    ...    \n",
       "ZI      16        47.562791\n",
       "        17       268.395349\n",
       "        18        93.986047\n",
       "        19       204.846512\n",
       "        20         1.320930\n",
       "Length: 5200, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9584"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.metric()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
