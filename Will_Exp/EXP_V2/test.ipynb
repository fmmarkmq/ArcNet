{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 CNN: 0.98\n",
    "1 CNN: 0.9615 epoch 3\n",
    "1 CNN: 0.9782 epoch 50\n",
    "ABC: 0.9575 batch 100, lr 0.0001, metrics criterion 'CE', epoch 3\n",
    "ABC: 0.9671 batch 100, lr 0.0001, metrics criterion 'CE', epoch 6\n",
    "ABC: 0.9768 epoch 50 kernel_per_pixel 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/wzong/anaconda3/envs/atd2022/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.tools import dotdict\n",
    "from driver.driver import ABC_Driver\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.set_device(6)\n",
    "import atd2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_args = dotdict()\n",
    "mnist_args.train = dotdict()\n",
    "mnist_args.predict = dotdict()\n",
    "\n",
    "mnist_args.name = 'mnist'\n",
    "mnist_args.train.batch_size = 60\n",
    "mnist_args.predict.batch_size = 100\n",
    "\n",
    "mnist_args.train_epochs= 3\n",
    "mnist_args.lr = 0.0001\n",
    "mnist_args.criterion = 'CE'\n",
    "mnist_args.use_gpu = True\n",
    "\n",
    "mnist_args.input_channel = 1\n",
    "mnist_args.input_height = 28\n",
    "mnist_args.input_width = 28\n",
    "mnist_args.kernel_size = 9\n",
    "mnist_args.knpp = 10\n",
    "mnist_args.knpp2 = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "atd_args = dotdict()\n",
    "atd_args.train = dotdict()\n",
    "\n",
    "atd_args.name = 'atd'\n",
    "atd_args.train.batch_size = 30\n",
    "atd_args.predict_len = 1\n",
    "atd_args.history_len = 5\n",
    "\n",
    "atd_args.train_epochs= 100\n",
    "atd_args.lr = 0.001\n",
    "atd_args.criterion = 'L1'\n",
    "atd_args.use_gpu = True\n",
    "\n",
    "atd_args.input_channel = atd_args.history_len\n",
    "atd_args.input_height = 1\n",
    "atd_args.input_width = 5200\n",
    "atd_args.kernel_size = 6\n",
    "atd_args.knpp = 6\n",
    "atd_args.knpp2 = atd_args.predict_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:None\n",
      "epoch: 0, train_loss: 1677.9812273297991\n",
      "epoch: 1, train_loss: 713.2244698660714\n",
      "epoch: 2, train_loss: 490.13682774135043\n",
      "epoch: 3, train_loss: 330.42532784598217\n",
      "epoch: 4, train_loss: 259.0156555175781\n",
      "epoch: 5, train_loss: 195.42953055245536\n",
      "epoch: 6, train_loss: 168.37197875976562\n",
      "epoch: 7, train_loss: 140.175416128976\n",
      "epoch: 8, train_loss: 128.48887852260046\n",
      "epoch: 9, train_loss: 115.18753269740513\n",
      "epoch: 10, train_loss: 107.58632550920758\n",
      "epoch: 11, train_loss: 102.3252944946289\n",
      "epoch: 12, train_loss: 99.1250501360212\n",
      "epoch: 13, train_loss: 96.6686771937779\n",
      "epoch: 14, train_loss: 95.21415383475167\n",
      "epoch: 15, train_loss: 93.94769941057477\n",
      "epoch: 16, train_loss: 92.8110842023577\n",
      "epoch: 17, train_loss: 91.53690011160714\n",
      "epoch: 18, train_loss: 90.53574044363839\n",
      "epoch: 19, train_loss: 88.89382825578961\n",
      "epoch: 20, train_loss: 87.39259120396206\n",
      "epoch: 21, train_loss: 86.03233228410993\n",
      "epoch: 22, train_loss: 84.85106004987445\n",
      "epoch: 23, train_loss: 84.01819501604352\n",
      "epoch: 24, train_loss: 82.99839564732143\n",
      "epoch: 25, train_loss: 81.82364109584263\n",
      "epoch: 26, train_loss: 80.77504512241909\n",
      "epoch: 27, train_loss: 79.59613146100726\n",
      "epoch: 28, train_loss: 78.37010083879743\n",
      "epoch: 29, train_loss: 77.81788199288505\n",
      "epoch: 30, train_loss: 76.65779331752232\n",
      "epoch: 31, train_loss: 75.38018907819476\n",
      "epoch: 32, train_loss: 74.77474866594586\n",
      "epoch: 33, train_loss: 73.89639500209263\n",
      "epoch: 34, train_loss: 72.92358071463448\n",
      "epoch: 35, train_loss: 71.57448141915458\n",
      "epoch: 36, train_loss: 70.97986275809151\n",
      "epoch: 37, train_loss: 70.56921822684151\n",
      "epoch: 38, train_loss: 69.87918199811664\n",
      "epoch: 39, train_loss: 68.83548409598214\n",
      "epoch: 40, train_loss: 68.33671242850167\n",
      "epoch: 41, train_loss: 67.83084324428013\n",
      "epoch: 42, train_loss: 67.02156393868583\n",
      "epoch: 43, train_loss: 66.56846291678292\n",
      "epoch: 44, train_loss: 65.95472063337054\n",
      "epoch: 45, train_loss: 65.510986328125\n",
      "epoch: 46, train_loss: 65.0910758972168\n",
      "epoch: 47, train_loss: 64.25586536952427\n",
      "epoch: 48, train_loss: 63.40836225237165\n",
      "epoch: 49, train_loss: 62.924591064453125\n",
      "epoch: 50, train_loss: 62.87891060965402\n",
      "epoch: 51, train_loss: 62.348026275634766\n",
      "epoch: 52, train_loss: 62.47958973475865\n",
      "epoch: 53, train_loss: 61.907059805733816\n",
      "epoch: 54, train_loss: 61.41158948625837\n",
      "epoch: 55, train_loss: 60.46502576555525\n",
      "epoch: 56, train_loss: 59.72833251953125\n",
      "epoch: 57, train_loss: 59.538783482142854\n",
      "epoch: 58, train_loss: 58.925127846854075\n",
      "epoch: 59, train_loss: 58.71975326538086\n",
      "epoch: 60, train_loss: 58.3295909336635\n",
      "epoch: 61, train_loss: 58.04087339128767\n",
      "epoch: 62, train_loss: 57.863433837890625\n",
      "epoch: 63, train_loss: 57.50818906511579\n",
      "epoch: 64, train_loss: 56.97448457990374\n",
      "epoch: 65, train_loss: 56.80566569737026\n",
      "epoch: 66, train_loss: 56.43929399762835\n",
      "epoch: 67, train_loss: 56.02694756644113\n",
      "epoch: 68, train_loss: 55.45381546020508\n",
      "epoch: 69, train_loss: 55.06497301374163\n",
      "epoch: 70, train_loss: 55.02900205339704\n",
      "epoch: 71, train_loss: 54.806977953229634\n",
      "epoch: 72, train_loss: 54.20868573869978\n",
      "epoch: 73, train_loss: 53.70691953386579\n",
      "epoch: 74, train_loss: 53.4063344682966\n",
      "epoch: 75, train_loss: 53.18574905395508\n",
      "epoch: 76, train_loss: 52.858890533447266\n",
      "epoch: 77, train_loss: 52.79801504952567\n",
      "epoch: 78, train_loss: 52.36903326851981\n",
      "epoch: 79, train_loss: 52.10990360804966\n",
      "epoch: 80, train_loss: 51.663818904331755\n",
      "epoch: 81, train_loss: 51.09520721435547\n",
      "epoch: 82, train_loss: 51.220259530203684\n",
      "epoch: 83, train_loss: 51.15437207903181\n",
      "epoch: 84, train_loss: 50.99724415370396\n",
      "epoch: 85, train_loss: 50.91316386631557\n",
      "epoch: 86, train_loss: 50.261562892368865\n",
      "epoch: 87, train_loss: 49.84217725481306\n",
      "epoch: 88, train_loss: 49.642888750348774\n",
      "epoch: 89, train_loss: 49.247615814208984\n",
      "epoch: 90, train_loss: 49.23788343157087\n",
      "epoch: 91, train_loss: 49.01515252249582\n",
      "epoch: 92, train_loss: 48.99323654174805\n",
      "epoch: 93, train_loss: 48.81618227277483\n",
      "epoch: 94, train_loss: 48.31589126586914\n",
      "epoch: 95, train_loss: 48.143336159842356\n",
      "epoch: 96, train_loss: 47.90365491594587\n",
      "epoch: 97, train_loss: 47.7144889831543\n",
      "epoch: 98, train_loss: 47.66005597795759\n",
      "epoch: 99, train_loss: 47.687467847551616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<driver.driver.ABC_Driver at 0x7f57e68ca3a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = atd_args\n",
    "data = atd2022.io.read_csv()\n",
    "# data = None\n",
    "driver = ABC_Driver(args, data)\n",
    "driver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:None\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/ABC/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f53cc9e3cf4629af2132f0aa3dee0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/ABC/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/ABC/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/ABC/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e71be2f7f6d492a8fb9179c82c1a60a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/ABC/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/ABC/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/ABC/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9a77b2d1164ee0ac8e82e5a1f04a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/ABC/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/ABC/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/ABC/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1376897d78d54f43a347ad6cc61f3207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/ABC/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/ABC/mnist/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = mnist_args\n",
    "driver = ABC_Driver(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (33600x28 and 784x784)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/wzong/Attention_based_CNN/Will_Exp/EXP_V2/driver/driver.py:42\u001b[0m, in \u001b[0;36mABC_Driver.train\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m     40\u001b[0m labels\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     41\u001b[0m model_optim\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 42\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(preds,labels)\n\u001b[1;32m     44\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/scratch/wzong/anaconda3/envs/atd2022/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/wzong/Attention_based_CNN/Will_Exp/EXP_V2/model/model.py:62\u001b[0m, in \u001b[0;36mABC_Net.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# B, -1, H, W\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(B, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpredict_len, H, W)\n",
      "File \u001b[0;32m/scratch/wzong/anaconda3/envs/atd2022/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/wzong/anaconda3/envs/atd2022/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (33600x28 and 784x784)"
     ]
    }
   ],
   "source": [
    "driver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
